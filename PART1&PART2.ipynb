{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["License check"],"metadata":{"id":"aEOIsfEdd3Ow"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8843313c","executionInfo":{"status":"ok","timestamp":1762201825517,"user_tz":300,"elapsed":10820,"user":{"displayName":"Victor Tenneroni","userId":"03459946062708176020"}},"outputId":"b8431ea1-2d8d-49c7-87c5-111fdd314d11"},"source":["!pip install gurobipy\n","import gurobipy as gp\n","from google.colab import userdata\n","\n","try:\n","    # Create an environment with your WLS license\n","    # Access secrets manager for WLSACCESSID and WLSSECRET\n","    params = {\n","        \"WLSACCESSID\": \"b92cfff8-0279-4652-9cb7-3e6bcdb967cd\",\n","        \"WLSSECRET\": \"e6220bd1-2657-40f8-ba01-6cebcb97db7fdesearc\",\n","        \"LICENSEID\": 2726201,\n","    }\n","    env = gp.Env(params=params)\n","\n","    print(\"Gurobi License Information:\")\n","    print(f\"  WLS Access ID: {env.getParam('WLSACCESSID')}\")\n","    print(f\"  WLS Secret: {env.getParam('WLSSECRET')}\")\n","    print(f\"  License ID: {env.getParam('LICENSEID')}\")\n","    # Accessing LicenseStatus directly might not always be possible or reliable\n","    # print(f\"  License Status: {env.getParam('LicenseStatus')}\")\n","\n","    # You might need to perform a simple operation to get more status details\n","    # For example, creating a simple model and optimizing it briefly\n","    # model = gp.Model(env=env)\n","    # model.addVar(name=\"dummy\")\n","    # model.setObjective(1.0, GRB.MINIMIZE)\n","    # model.optimize()\n","    # print(f\"  Gurobi Status (after dummy optimization): {model.Status}\")\n","    # del model # Clean up the dummy model\n","\n","\n","except gp.GurobiError as e:\n","    print(f\"Error creating Gurobi environment or retrieving license information: {e}\")\n","    print(\"Please ensure your WLS license details (WLSACCESSID, WLSSECRET, LICENSEID) are correct.\")\n","except Exception as e:\n","    print(f\"An unexpected error occurred: {e}\")"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gurobipy\n","  Downloading gurobipy-12.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (16 kB)\n","Downloading gurobipy-12.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (14.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.3/14.3 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: gurobipy\n","Successfully installed gurobipy-12.0.3\n","Set parameter WLSAccessID\n","Set parameter WLSSecret\n","Set parameter LicenseID to value 2726201\n","Error creating Gurobi environment or retrieving license information: Unauthorized access\n","Please ensure your WLS license details (WLSACCESSID, WLSSECRET, LICENSEID) are correct.\n"]}]},{"cell_type":"markdown","source":["# Cleaning"],"metadata":{"id":"KNNah9FZXJyk"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3_hS5U3Ab4T7","executionInfo":{"status":"ok","timestamp":1762201848740,"user_tz":300,"elapsed":23221,"user":{"displayName":"Victor Tenneroni","userId":"03459946062708176020"}},"outputId":"2838e4e5-b6b2-4855-b3f3-29cf8b7f72a9"},"outputs":[{"output_type":"stream","name":"stdout","text":["✓ gurobipy installed/available\n","Mounted at /content/drive\n","Google Drive mounted\n","DATA_PATH: /content/drive/MyDrive/IEORE4004 Optimization Models and Methods/IEOR4404_Proj1/data/\n","OUTPUT_PATH: /content/drive/MyDrive/IEORE4004 Optimization Models and Methods/IEOR4404_Proj1/cleaned_data/\n","DATA exists: True\n","Loaded shapes: fac (15604, 15) pop (1646, 20) inc (1534, 2) emp (1375, 2) loc (215400, 3)\n","✓ imputed facility coordinates; nulls: {'latitude': 0, 'longitude': 0}\n","✓ standardized column names\n","✓ zipcodes normalized to str zfill(5)\n","✓ computed & saved H025/H512: /content/drive/MyDrive/IEORE4004 Optimization Models and Methods/IEOR4404_Proj1/cleaned_data/zip_capacity_by_age.csv\n","✓ wrote /content/drive/MyDrive/IEORE4004 Optimization Models and Methods/IEOR4404_Proj1/cleaned_data/facilities_clean.csv\n","✓ wrote /content/drive/MyDrive/IEORE4004 Optimization Models and Methods/IEOR4404_Proj1/cleaned_data/zipcode_master_reconciled.csv\n","✓ built population aggregates\n","Total 0–12: 2812163\n","✓ facilities_agg: (1604, 3)\n","✓ master zipcode list: 2594\n","✓ merged master with population/income/employment/facilities + H025/H512\n","Missing values:\n"," zipcode                       0\n","pop_0_5                     948\n","pop_5_12                    948\n","pop_0_12                    948\n","avg_income                 1060\n","employment_rate            1219\n","total_existing_slots          0\n","num_existing_facilities       0\n","H025_zip                      0\n","H512_zip                      0\n","dtype: int64\n","⚠️ Missing population: 948 | income: 1060 | employment: 1219\n","✓ cleaned zipcodes: 2594 → 1375 (dropped 1219)\n","✓ derived fields added\n","============================================================\n","CLEANED DATA SUMMARY\n","============================================================\n","Zipcodes: 1375 | Deserts: 1240 (90.2%)\n","High-demand: 561 (40.8%)\n","Zero-facility zips: 363\n","Total children 0–12: 2,795,679\n","Total children 0–5 : 1,065,208\n","Total existing slots: 607,494\n","Overall coverage ratio: 0.217\n","✓ facilities cleaned: (14435, 5)\n","✓ locations cleaned: (137500, 4)\n","✓ saved zipcode_master.csv / facilities_clean.csv / locations_clean.csv / zip_capacity_by_age.csv\n","✓ rewrote zipcode_master_reconciled.csv\n","\n","VALIDATION REPORT\n","============================================================\n","Critical nulls: 0\n","Desert logic (high-demand): True\n","Desert logic (normal)    : True\n","Population math correct  : True\n","============================================================\n","DONE\n","✓ defined 'pl' and 'zipdf' dataframes from cleaned data\n"]}],"source":["# =========================================\n","# Cell A — install packages (gurobipy)\n","# =========================================\n","import sys, subprocess, importlib\n","def _pip_install(pkg):\n","    try:\n","        importlib.import_module(pkg)\n","    except ImportError:\n","        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n","_pip_install(\"gurobipy\")\n","print(\"✓ gurobipy installed/available\")\n","\n","# =========================================\n","# Cell B — mount Google Drive & set paths\n","# =========================================\n","try:\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount=True)\n","    print(\"Google Drive mounted\")\n","except Exception as e:\n","    print(\"Not in Colab or Drive mount failed:\", e)\n","\n","import os\n","import pandas as pd\n","import numpy as np\n","\n","BASE_PATH   = '/content/drive/MyDrive/IEORE4004 Optimization Models and Methods/'\n","DATA_PATH   = os.path.join(BASE_PATH, 'IEOR4404_Proj1/data/')\n","OUTPUT_PATH = os.path.join(BASE_PATH, 'IEOR4404_Proj1/cleaned_data/')\n","os.makedirs(OUTPUT_PATH, exist_ok=True)\n","print(\"DATA_PATH:\", DATA_PATH)\n","print(\"OUTPUT_PATH:\", OUTPUT_PATH)\n","print(\"DATA exists:\", os.path.exists(DATA_PATH))\n","\n","# =========================================\n","# Cell C — load csvs\n","# =========================================\n","def _read_csv(path, **kwargs):\n","    if not os.path.exists(path):\n","        raise FileNotFoundError(f\"Missing file: {path}\")\n","    return pd.read_csv(path, **kwargs)\n","\n","df_facilities  = _read_csv(os.path.join(DATA_PATH, 'child_care_regulated.csv'))\n","df_population  = _read_csv(os.path.join(DATA_PATH, 'population.csv'))\n","df_income      = _read_csv(os.path.join(DATA_PATH, 'avg_individual_income.csv'))\n","df_employment  = _read_csv(os.path.join(DATA_PATH, 'employment_rate.csv'))\n","df_locations   = _read_csv(os.path.join(DATA_PATH, 'potential_locations.csv'))\n","\n","print(\"Loaded shapes:\",\n","      \"fac\", df_facilities.shape,\n","      \"pop\", df_population.shape,\n","      \"inc\", df_income.shape,\n","      \"emp\", df_employment.shape,\n","      \"loc\", df_locations.shape)\n","\n","# =========================================\n","# Cell D — impute facility coordinates\n","# =========================================\n","zip_col_loc = 'zip_code' if 'zip_code' in df_locations.columns else 'zipcode'\n","zip_col_fac = 'zip_code' if 'zip_code' in df_facilities.columns else 'zipcode'\n","\n","_zip = df_locations.dropna(subset=['latitude','longitude']).copy()\n","_zip[zip_col_loc] = _zip[zip_col_loc].astype(str)\n","\n","centroids = (\n","    _zip.groupby(zip_col_loc, as_index=False)[['latitude','longitude']]\n","        .mean()\n","        .rename(columns={'latitude':'lat_centroid','longitude':'lon_centroid'})\n",")\n","\n","_fac = df_facilities.copy()\n","_fac[zip_col_fac] = _fac[zip_col_fac].astype(str)\n","_fac = _fac.merge(centroids, left_on=zip_col_fac, right_on=zip_col_loc, how='left')\n","\n","fac_means = (\n","    _fac.dropna(subset=['latitude','longitude'])\n","        .groupby(zip_col_fac)[['latitude','longitude']].mean()\n","        .rename(columns={'latitude':'lat_zip_fac_mean','longitude':'lon_zip_fac_mean'})\n",")\n","_fac = _fac.join(fac_means, on=zip_col_fac)\n","\n","global_lat = _zip['latitude'].mean() if not _zip.empty else df_facilities['latitude'].mean()\n","global_lon = _zip['longitude'].mean() if not _zip.empty else df_facilities['longitude'].mean()\n","\n","_fac['latitude']  = _fac['latitude'].fillna(_fac.get('lat_centroid')).fillna(_fac.get('lat_zip_fac_mean')).fillna(global_lat)\n","_fac['longitude'] = _fac['longitude'].fillna(_fac.get('lon_centroid')).fillna(_fac.get('lon_zip_fac_mean')).fillna(global_lon)\n","\n","df_facilities[['latitude','longitude']] = _fac[['latitude','longitude']]\n","print(\"✓ imputed facility coordinates; nulls:\",\n","      df_facilities[['latitude','longitude']].isna().sum().to_dict())\n","\n","# =========================================\n","# Cell E — standardize columns\n","# =========================================\n","df_facilities.rename(columns={'zip_code':'zipcode', 'total_capacity':'capacity'}, inplace=True)\n","df_income.rename(columns={'ZIP code':'zipcode', 'average income':'avg_income'}, inplace=True)\n","df_employment.rename(columns={'employment rate':'employment_rate'}, inplace=True)\n","print(\"✓ standardized column names\")\n","\n","# normalize zipcode dtype early (str + zfill(5))\n","for df_ in [df_facilities, df_population, df_income, df_employment, df_locations]:\n","    if 'zipcode' in df_.columns:\n","        df_['zipcode'] = df_['zipcode'].astype(str).str.zfill(5)\n","print(\"✓ zipcodes normalized to str zfill(5)\")\n","\n","# =========================================\n","# Cell F — compute H025/H512 with residual allocation (FIX)\n","# =========================================\n","fac = df_facilities.copy()\n","fac['h025_base'] = fac[['infant_capacity','toddler_capacity','preschool_capacity']].fillna(0).sum(axis=1)\n","fac['h512_base'] = fac['school_age_capacity'].fillna(0)\n","fac['residual']  = (fac['capacity'] - (fac['h025_base'] + fac['h512_base'])).clip(lower=0)\n","\n","# zip-level share_0_5 from population (0–5 / (0–5 + 0.795778952*(5–9 + 10–14)))\n","# https://www.census.gov/data/tables/time-series/demo/popest/2020s-state-detail.html\n","\n","pop_share = (\n","    df_population.assign(\n","        share_0_5 = df_population['-5'] /\n","                    (df_population['-5'] + 0.795778952*(df_population['5-9'] + df_population['10-14']))\n","    )[[\"zipcode\",\"share_0_5\"]]\n",")\n","pop_share['share_0_5'] = pop_share['share_0_5'].replace([np.inf, -np.inf], np.nan)\n","pop_share['share_0_5'] = pop_share['share_0_5'].fillna(pop_share['share_0_5'].mean())\n","\n","fac = fac.merge(pop_share, on='zipcode', how='left')\n","fac['H025_facility'] = fac['h025_base'] + fac['residual'] * fac['share_0_5'].fillna(0.38)\n","fac['H512_facility'] = fac['h512_base'] + fac['residual'] * (1 - fac['share_0_5'].fillna(0.38))\n","\n","zip_capacity_by_age = (\n","    fac.groupby('zipcode', as_index=False)\n","       .agg(H025_zip=('H025_facility','sum'),\n","            H512_zip=('H512_facility','sum'),\n","            total_capacity=('capacity','sum'),\n","            facility_count=('facility_id','count'))\n",")\n","zip_out = os.path.join(OUTPUT_PATH, 'zip_capacity_by_age.csv')\n","zip_capacity_by_age.to_csv(zip_out, index=False)\n","print(\"✓ computed & saved H025/H512:\", zip_out)\n","\n","# =========================================\n","# Cell G — save enriched facilities now (for downstream)\n","# =========================================\n","fac_out = os.path.join(OUTPUT_PATH, 'facilities_clean.csv')\n","df_facilities.to_csv(fac_out, index=False)\n","print(\"✓ wrote\", fac_out)\n","\n","# =========================================\n","# Cell H — reconcile totals (dtype-safe) and write zipcode_master_reconciled.csv (FIX)\n","# =========================================\n","fac_zip = df_facilities.copy()\n","fac_zip['zipcode'] = fac_zip['zipcode'].astype(str).str.zfill(5)\n","\n","cap_by_zip = (\n","    fac_zip.groupby('zipcode', as_index=False)['capacity']\n","           .sum()\n","           .rename(columns={'capacity': 'capacity_from_fac'})\n",")\n","\n","# try load an existing master (dtype=str); else start from cap_by_zip\n","candidates = [\n","    os.path.join(OUTPUT_PATH, 'zipcode_master.csv'),\n","    os.path.join(OUTPUT_PATH, 'zipcode_master_reconciled.csv'),\n","    os.path.join(DATA_PATH,   'zipcode_master.csv')\n","]\n","master_path = next((p for p in candidates if os.path.exists(p)), None)\n","if master_path:\n","    zipcode_master = pd.read_csv(master_path, dtype={'zipcode': str})\n","else:\n","    zipcode_master = cap_by_zip[['zipcode']].copy()\n","\n","zipcode_master['zipcode'] = zipcode_master['zipcode'].astype(str).str.zfill(5)\n","cap_by_zip['zipcode']      = cap_by_zip['zipcode'].astype(str).str.zfill(5)\n","\n","zipcode_master = zipcode_master.merge(cap_by_zip, on='zipcode', how='left')\n","\n","if 'total_existing_slots' in zipcode_master.columns:\n","    zipcode_master['gap_vs_old'] = zipcode_master['total_existing_slots'] - zipcode_master['capacity_from_fac']\n","\n","zipcode_master['total_existing_slots'] = zipcode_master['capacity_from_fac'].fillna(0)\n","\n","# add current coverage ratio if population is present\n","if 'pop_0_12' in zipcode_master.columns:\n","    zipcode_master['current_coverage_ratio'] = zipcode_master['total_existing_slots'] / zipcode_master['pop_0_12'].replace(0, np.nan)\n","\n","outp_recon = os.path.join(OUTPUT_PATH, 'zipcode_master_reconciled.csv')\n","zipcode_master.to_csv(outp_recon, index=False)\n","print(\"✓ wrote\", outp_recon)\n","\n","# =========================================\n","# Cell I — compute population groups (0–5, 5–12, 0–12)\n","# =========================================\n","df_population_clean = df_population[['zipcode','-5','5-9','10-14']].copy()\n","df_population_clean['pop_0_5']  = df_population_clean['-5']\n","df_population_clean['pop_5_12'] = 0.7957 * (df_population_clean['5-9'] + df_population_clean['10-14']) # from nys census data 2020-2024\n","df_population_clean['pop_0_12'] = df_population_clean['pop_0_5'] + df_population_clean['pop_5_12']\n","df_population_clean['pop_5_12'] = df_population_clean['pop_5_12'].round()\n","df_population_clean['pop_0_12'] = df_population_clean['pop_0_12'].round()\n","df_population_clean = df_population_clean[['zipcode','pop_0_5','pop_5_12','pop_0_12']]\n","\n","print(\"✓ built population aggregates\")\n","print(\"Total 0–12:\", int(df_population_clean['pop_0_12'].sum()))\n","\n","# =========================================\n","# Cell J — aggregate facilities by zip\n","# =========================================\n","facilities_agg = (\n","    df_facilities.groupby('zipcode', as_index=False)\n","                 .agg(total_existing_slots=('capacity','sum'),\n","                      num_existing_facilities=('facility_id','count'))\n",")\n","print(\"✓ facilities_agg:\", facilities_agg.shape)\n","\n","# =========================================\n","# Cell K — master zipcode list\n","# =========================================\n","all_zipcodes = set()\n","for df_ in [df_facilities, df_population_clean, df_income, df_employment, df_locations]:\n","    if 'zipcode' in df_.columns:\n","        all_zipcodes.update(df_['zipcode'].astype(str).str.zfill(5).unique())\n","df_master = pd.DataFrame({'zipcode': sorted(list(all_zipcodes))})\n","print(\"✓ master zipcode list:\", len(df_master))\n","\n","# =========================================\n","# Cell L — merge all data (and keep H025/H512) (FIX)\n","# =========================================\n","df_master['zipcode']             = df_master['zipcode'].astype(str).str.zfill(5)\n","df_population_clean['zipcode']   = df_population_clean['zipcode'].astype(str).str.zfill(5)\n","df_income['zipcode']             = df_income['zipcode'].astype(str).str.zfill(5)\n","df_employment['zipcode']         = df_employment['zipcode'].astype(str).str.zfill(5)\n","facilities_agg['zipcode']        = facilities_agg['zipcode'].astype(str).str.zfill(5)\n","zip_capacity_by_age['zipcode']   = zip_capacity_by_age['zipcode'].astype(str).str.zfill(5)\n","\n","df_master = df_master.merge(df_population_clean, on='zipcode', how='left')\n","df_master = df_master.merge(df_income[['zipcode','avg_income']], on='zipcode', how='left')\n","df_master = df_master.merge(df_employment[['zipcode','employment_rate']], on='zipcode', how='left')\n","df_master = df_master.merge(facilities_agg, on='zipcode', how='left')\n","df_master['total_existing_slots']   = df_master['total_existing_slots'].fillna(0)\n","df_master['num_existing_facilities']= df_master['num_existing_facilities'].fillna(0)\n","\n","# merge 0–5 / 5–12 baselines\n","df_master = df_master.merge(zip_capacity_by_age[['zipcode','H025_zip','H512_zip']], on='zipcode', how='left')\n","df_master[['H025_zip','H512_zip']] = df_master[['H025_zip','H512_zip']].fillna(0)\n","\n","print(\"✓ merged master with population/income/employment/facilities + H025/H512\")\n","print(\"Missing values:\\n\", df_master.isnull().sum())\n","\n","# =========================================\n","# Cell M — identify data quality issues\n","# =========================================\n","missing_pop        = df_master[df_master['pop_0_12'].isnull()]\n","missing_income     = df_master[df_master['avg_income'].isnull()]\n","missing_employment = df_master[df_master['employment_rate'].isnull()]\n","print(f\"⚠️ Missing population: {len(missing_pop)} | income: {len(missing_income)} | employment: {len(missing_employment)}\")\n","\n","# =========================================\n","# Cell N — drop rows missing critical fields\n","# =========================================\n","before = len(df_master)\n","df_clean = df_master.dropna(subset=['pop_0_12','avg_income','employment_rate']).copy()\n","after = len(df_clean)\n","print(f\"✓ cleaned zipcodes: {before} → {after} (dropped {before-after})\")\n","assert df_clean[['pop_0_12','pop_0_5','pop_5_12','avg_income','employment_rate']].isnull().sum().sum() == 0\n","\n","# =========================================\n","# Cell O — derived fields (Problem 1: budgeting) (no 0–5 constraint enforced here)\n","# =========================================\n","df_clean['high_demand'] = ((df_clean['employment_rate'] >= 0.60) | (df_clean['avg_income'] <= 60000)).astype(int)\n","df_clean['desert_threshold'] = np.where(\n","    df_clean['high_demand'] == 1,\n","    0.5 * df_clean['pop_0_12'],\n","    0.33 * df_clean['pop_0_12']\n",")\n","\n","df_clean['is_desert'] = (df_clean['total_existing_slots'] <= df_clean['desert_threshold']).astype(int)\n","df_clean['current_coverage_ratio'] = df_clean['total_existing_slots'] / df_clean['pop_0_12'].replace(0, np.nan)\n","print(\"✓ derived fields added\")\n","\n","# =========================================\n","# Cell P — summary\n","# =========================================\n","print(\"=\"*60)\n","print(\"CLEANED DATA SUMMARY\")\n","print(\"=\"*60)\n","print(f\"Zipcodes: {len(df_clean)} | Deserts: {df_clean['is_desert'].sum()} ({100*df_clean['is_desert'].mean():.1f}%)\")\n","print(f\"High-demand: {df_clean['high_demand'].sum()} ({100*df_clean['high_demand'].mean():.1f}%)\")\n","print(f\"Zero-facility zips: {(df_clean['total_existing_slots'] == 0).sum()}\")\n","print(f\"Total children 0–12: {int(df_clean['pop_0_12'].sum()):,}\")\n","print(f\"Total children 0–5 : {int(df_clean['pop_0_5'].sum()):,}\")\n","print(f\"Total existing slots: {int(df_clean['total_existing_slots'].sum()):,}\")\n","print(f\"Overall coverage ratio: {df_clean['total_existing_slots'].sum() / df_clean['pop_0_12'].sum():.3f}\")\n","\n","# =========================================\n","# Cell Q — clean facilities for downstream optimization\n","# =========================================\n","valid_zipcodes = set(df_clean['zipcode'].unique())\n","df_facilities_clean = df_facilities[df_facilities['zipcode'].isin(valid_zipcodes)].copy()\n","df_facilities_clean = df_facilities_clean.dropna(subset=['capacity','latitude','longitude']).copy()\n","df_facilities_clean = df_facilities_clean[['facility_id','zipcode','capacity','latitude','longitude']]\n","print(\"✓ facilities cleaned:\", df_facilities_clean.shape)\n","\n","# =========================================\n","# Cell R — clean potential locations\n","# =========================================\n","df_locations_clean = df_locations[df_locations['zipcode'].isin(valid_zipcodes)].copy()\n","df_locations_clean = df_locations_clean.reset_index(drop=True)\n","df_locations_clean['location_id'] = range(len(df_locations_clean))\n","print(\"✓ locations cleaned:\", df_locations_clean.shape)\n","\n","# =========================================\n","# Cell S — save all cleaned outputs\n","# =========================================\n","df_clean.to_csv(os.path.join(OUTPUT_PATH, 'zipcode_master.csv'), index=False)\n","df_facilities_clean.to_csv(os.path.join(OUTPUT_PATH, 'facilities_clean.csv'), index=False)\n","df_locations_clean.to_csv(os.path.join(OUTPUT_PATH, 'locations_clean.csv'), index=False)\n","zip_capacity_by_age.to_csv(os.path.join(OUTPUT_PATH, 'zip_capacity_by_age.csv'), index=False)\n","print(\"✓ saved zipcode_master.csv / facilities_clean.csv / locations_clean.csv / zip_capacity_by_age.csv\")\n","\n","# also (re)write reconciled using the authoritative facility sum already computed above\n","zipcode_master_reconciled = df_clean.copy()\n","# ensure reconciled carries the authoritative totals (capacity_from_fac)\n","cap_from_fac = cap_by_zip.rename(columns={'capacity_from_fac':'total_existing_slots'})\n","zipcode_master_reconciled = zipcode_master_reconciled.drop(columns=['total_existing_slots'], errors='ignore')\n","zipcode_master_reconciled = zipcode_master_reconciled.merge(cap_from_fac, on='zipcode', how='left')\n","zipcode_master_reconciled['total_existing_slots'] = zipcode_master_reconciled['total_existing_slots'].fillna(0)\n","zipcode_master_reconciled.to_csv(os.path.join(OUTPUT_PATH, 'zipcode_master_reconciled.csv'), index=False)\n","print(\"✓ rewrote zipcode_master_reconciled.csv\")\n","\n","# =========================================\n","# Cell T — quick validation report (non-fatal)\n","# =========================================\n","print(\"\\nVALIDATION REPORT\")\n","print(\"=\"*60)\n","crit_nulls = df_clean[['zipcode','pop_0_12','pop_0_5','pop_5_12','avg_income','employment_rate']].isnull().sum().sum()\n","print(\"Critical nulls:\", crit_nulls)\n","desert_logic_high = ((df_clean[df_clean['high_demand']==1]['is_desert'] ==\n","                      (df_clean[df_clean['high_demand']==1]['total_existing_slots'] <= 0.5*df_clean[df_clean['high_demand']==1]['pop_0_12'])).all())\n","desert_logic_norm = ((df_clean[df_clean['high_demand']==0]['is_desert'] ==\n","                      (df_clean[df_clean['high_demand']==0]['total_existing_slots'] <= 0.33*df_clean[df_clean['high_demand']==0]['pop_0_12'])).all())\n","print(\"Desert logic (high-demand):\", desert_logic_high)\n","print(\"Desert logic (normal)    :\", desert_logic_norm)\n","pop_math = (df_clean['pop_0_5'] + df_clean['pop_5_12'] == df_clean['pop_0_12']).all()\n","print(\"Population math correct  :\", pop_math)\n","print(\"=\"*60)\n","print(\"DONE\")\n","\n","# Assign cleaned dataframes to names expected by downstream cells\n","pl = df_locations_clean.copy()\n","zipdf = df_clean.copy() # Assign df_clean to zipdf\n","print(\"✓ defined 'pl' and 'zipdf' dataframes from cleaned data\")"]},{"cell_type":"code","source":["print(\"Total facilities (raw, unique IDs):\", df_facilities['facility_id'].nunique())\n","print(\"Total facilities (raw, rows):\", len(df_facilities))\n","\n","print(\"Total facilities (cleaned):\", len(df_facilities_clean))\n","print(\"Sum of per-ZIP counts (facilities_agg):\", int(facilities_agg['num_existing_facilities'].sum()))\n","print(\"Sum of per-ZIP counts (zip_capacity_by_age):\", int(zip_capacity_by_age['facility_count'].sum()))\n"],"metadata":{"id":"zW3o1FDVwgp5","executionInfo":{"status":"ok","timestamp":1762201848791,"user_tz":300,"elapsed":50,"user":{"displayName":"Victor Tenneroni","userId":"03459946062708176020"}},"outputId":"ad4e5b02-f362-46fc-9704-025aecfd618b","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Total facilities (raw, unique IDs): 15604\n","Total facilities (raw, rows): 15604\n","Total facilities (cleaned): 14435\n","Sum of per-ZIP counts (facilities_agg): 15604\n","Sum of per-ZIP counts (zip_capacity_by_age): 15604\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"RNK1Pfwxwgy-","executionInfo":{"status":"ok","timestamp":1762201848795,"user_tz":300,"elapsed":2,"user":{"displayName":"Victor Tenneroni","userId":"03459946062708176020"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# Part 1"],"metadata":{"id":"KEaJdqyFcCrW"}},{"cell_type":"markdown","source":["## Optimiation\n","fixed the 200 per existing spot, and 200000 baseline, i think"],"metadata":{"id":"VWn2vwYrAx5x"}},{"cell_type":"code","source":["# ===========================\n","# Step 1 — install & imports\n","# ===========================\n","import sys, subprocess, importlib, os\n","\n","def _pip_install(pkg):\n","    try:\n","        importlib.import_module(pkg)\n","    except ImportError:\n","        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n","\n","for _pkg in (\"gurobipy\",\"pandas\",\"numpy\"):\n","    _pip_install(_pkg)\n","\n","import pandas as pd\n","import numpy as np\n","import gurobipy as gp\n","from gurobipy import GRB\n","\n","# ================================\n","# Step 2 — mount Drive & set paths\n","# ================================\n","try:\n","    from google.colab import drive\n","    drive.mount(\"/content/drive\", force_remount=True)\n","    print(\"✓ Google Drive mounted.\")\n","except Exception as e:\n","    print(\"Not in Colab or Drive mount failed:\", e)\n","\n","BASE_PATH   = \"/content/drive/MyDrive/IEORE4004 Optimization Models and Methods/\"\n","DATA_PATH   = os.path.join(BASE_PATH, \"IEOR4404_Proj1/data/\")\n","OUTPUT_PATH = os.path.join(BASE_PATH, \"IEOR4404_Proj1/cleaned_data/\")\n","os.makedirs(OUTPUT_PATH, exist_ok=True)\n","print(\"DATA_PATH:\", DATA_PATH)\n","print(\"OUTPUT_PATH:\", OUTPUT_PATH)\n","\n","# ===========================================\n","# Step 3 — load cleaned inputs (dtype-safe zips)\n","# ===========================================\n","def _read_csv_safe(path, dtype_zip=True):\n","    if not os.path.exists(path):\n","        raise FileNotFoundError(f\"Missing file: {path}\")\n","    if dtype_zip:\n","        return pd.read_csv(path, dtype={\"zipcode\": str})\n","    return pd.read_csv(path)\n","\n","master_path_csv = os.path.join(OUTPUT_PATH, \"zipcode_master.csv\")\n","fac_path_csv    = os.path.join(OUTPUT_PATH, \"facilities_clean.csv\")\n","loc_path_csv    = os.path.join(OUTPUT_PATH, \"locations_clean.csv\")\n","zipage_path_csv = os.path.join(OUTPUT_PATH, \"zip_capacity_by_age.csv\")\n","\n","master = _read_csv_safe(master_path_csv)\n","fac    = _read_csv_safe(fac_path_csv)\n","locs   = _read_csv_safe(loc_path_csv)\n","zipage = _read_csv_safe(zipage_path_csv)\n","\n","# normalize zipcode format\n","for df_ in (master, fac, locs, zipage):\n","    if \"zipcode\" in df_.columns:\n","        df_[\"zipcode\"] = df_[\"zipcode\"].astype(str).str.zfill(5)\n","\n","# quick guards: required columns\n","req_master = {\"zipcode\",\"pop_0_12\",\"total_existing_slots\",\"desert_threshold\"}\n","missing_master_cols = req_master - set(master.columns)\n","if missing_master_cols:\n","    raise ValueError(f\"zipcode_master.csv missing columns: {missing_master_cols}\")\n","\n","req_fac = {\"facility_id\",\"zipcode\",\"capacity\"}\n","if not req_fac.issubset(set(fac.columns)):\n","    raise ValueError(f\"facilities_clean.csv missing columns: {req_fac - set(fac.columns)}\")\n","\n","# synthesize location_id if missing\n","if \"location_id\" not in locs.columns:\n","    locs = locs.reset_index(drop=True)\n","    locs[\"location_id\"] = np.arange(len(locs))\n","\n","req_locs = {\"location_id\",\"zipcode\"}\n","if not req_locs.issubset(set(locs.columns)):\n","    raise ValueError(f\"locations_clean.csv missing columns: {req_locs - set(locs.columns)}\")\n","\n","print(\"✓ Loaded cleaned inputs.\",\n","      \"\\n master:\", master.shape,\n","      \"\\n fac   :\", fac.shape,\n","      \"\\n locs  :\", locs.shape,\n","      \"\\n zipage:\", zipage.shape)\n","\n","# ======================================================\n","# Step 4 — create Gurobi WLS environment\n","# ======================================================\n","params = {\n","    \"WLSACCESSID\": \"b92cfff8-0279-4652-9cb7-3e6bcdb967cd\",\n","    \"WLSSECRET\":   \"e6220bd1-2657-40f8-ba01-6cebcb97db7f\",\n","    \"LICENSEID\":   2726201,\n","}\n","env = gp.Env(params=params)\n","print(\"✓ Gurobi WLS environment created.\")\n","\n","# =================================================================\n","# Step 5 — sets/parameters (Problem 1: C1 + C2)\n","# =================================================================\n","# Sets\n","Z = sorted(master[\"zipcode\"].unique().tolist())\n","F = fac[\"facility_id\"].astype(int).tolist()\n","P = locs[\"location_id\"].astype(int).tolist()\n","TYPES = [\"S\",\"M\",\"L\"]\n","\n","# Index maps\n","z_of_f = dict(zip(fac[\"facility_id\"].astype(int), fac[\"zipcode\"]))\n","z_of_p = dict(zip(locs[\"location_id\"].astype(int), locs[\"zipcode\"]))\n","\n","# Parameters\n","K_total = {\"S\":100, \"M\":200, \"L\":400}\n","K_0_5   = {\"S\": 50, \"M\":100, \"L\":200}\n","c_build = {\"S\": 65000, \"M\": 95000, \"L\":115000}\n","c_equip = 100.0  # per 0–5 slot equipment cost\n","\n","# corrected expansion charging:\n","# if expand by >=100% at facility f (x_f >= current capacity nf), pay a fixed cost:\n","# 20000 + 200 * nf, once per such facility (not per added slot)\n","baseline_cost = 20000.0\n","\n","# Existing facility capacity & P1 bounds (add <=120% of current, total cap <=500)\n","Cnow_f = dict(zip(fac[\"facility_id\"].astype(int), fac[\"capacity\"]))\n","xmax_f = {}\n","for f_id in F:\n","    cnow = float(Cnow_f.get(f_id, 0.0))\n","    add_cap_120 = 1.2 * cnow\n","    room_to_500 = max(0.0, 500.0 - cnow)\n","    xmax_f[f_id] = min(add_cap_120, room_to_500)\n","\n","# ZIP-level totals for 0–12 (C1 target in slots)\n","Cnow_tot     = dict(zip(master[\"zipcode\"], master[\"total_existing_slots\"]))\n","Target_slots = dict(zip(master[\"zipcode\"], master[\"desert_threshold\"]))\n","\n","# ZIP-level 0–5 data (C2 target)\n","if \"pop_0_5\" in master.columns:\n","    N0_5_series = master.set_index(\"zipcode\")[\"pop_0_5\"].astype(float)\n","elif \"pop_0_5\" in zipage.columns:\n","    N0_5_series = zipage.groupby(\"zipcode\")[\"pop_0_5\"].sum().astype(float)\n","else:\n","    raise ValueError(\"Need pop_0_5 in master or zip_capacity_by_age.csv for C2.\")\n","\n","if \"H025_zip\" in master.columns:\n","    Cnow_05_series = master.set_index(\"zipcode\")[\"H025_zip\"].astype(float)\n","elif \"H025_zip\" in zipage.columns:\n","    Cnow_05_series = zipage.groupby(\"zipcode\")[\"H025_zip\"].sum().astype(float)\n","else:\n","    raise ValueError(\"Need H025_zip in master or zip_capacity_by_age.csv for C2.\")\n","\n","# Align to full ZIP index Z\n","N0_5_series = N0_5_series.reindex(Z).fillna(0.0)\n","Cnow_05_series = Cnow_05_series.reindex(Z).fillna(0.0)\n","\n","# Convenience: entities in each ZIP\n","Fz = {z: [f_id for f_id in F if z_of_f[f_id] == z] for z in Z}\n","Pz = {z: [p_id for p_id in P if z_of_p[p_id] == z] for z in Z}\n","\n","# Deficits and needy ZIPs\n","tau_05 = 2.0/3.0\n","deficit12_by_zip = {z: max(0.0, float(Target_slots.get(z,0.0)) - float(Cnow_tot.get(z,0.0))) for z in Z}\n","deficit05_by_zip = {z: max(0.0, float(tau_05 * N0_5_series.loc[z]) - float(Cnow_05_series.loc[z])) for z in Z}\n","\n","needy_12 = [z for z in Z if deficit12_by_zip[z] > 1e-6]\n","needy_05 = [z for z in Z if deficit05_by_zip[z] > 1e-6]\n","need_union = sorted(set(needy_12) | set(needy_05))\n","\n","# Filter candidate sites to union of needy ZIPs\n","P = [p for p in P if z_of_p[p] in need_union]\n","Pz = {z: [p for p in P if z_of_p[p] == z] for z in Z}\n","print(f\"ZIPs with need — C1: {len(needy_12)}, C2: {len(needy_05)}, union: {len(need_union)}; kept sites: {len(P)}\")\n","\n","# Optional: cap sites per ZIP\n","MAX_SITES_PER_ZIP = 20\n","if MAX_SITES_PER_ZIP is not None:\n","    keepP = []\n","    for z in need_union:\n","        keepP.extend(Pz[z][:MAX_SITES_PER_ZIP])\n","    P = sorted(set(keepP))\n","    Pz = {z: [p for p in P if z_of_p[p] == z] for z in Z}\n","    print(f\"Sites after per-ZIP cap ({MAX_SITES_PER_ZIP}): {len(P)}\")\n","\n","# Quick feasibility upper bounds per ZIP\n","def max_supply_12(z):\n","    return sum(xmax_f.get(f,0.0) for f in Fz[z]) + len(Pz[z]) * K_total['L']\n","def max_supply_05(z):\n","    return sum(xmax_f.get(f,0.0) for f in Fz[z]) + len(Pz[z]) * K_0_5['L']\n","\n","bad_12 = [z for z in Z if deficit12_by_zip[z] > max_supply_12(z) + 1e-6]\n","bad_05 = [z for z in Z if deficit05_by_zip[z] > max_supply_05(z) + 1e-6]\n","print(\"C1 impossible ZIPs:\", len(bad_12), bad_12[:10])\n","print(\"C2 impossible ZIPs:\", len(bad_05), bad_05[:10])\n","\n","needy_12 = [z for z in needy_12 if z not in bad_12]\n","needy_05 = [z for z in needy_05 if z not in bad_05]\n","\n","# ==========================================\n","# Step 6 — build model (Problem 1: C1 + C2)\n","# ==========================================\n","m = gp.Model(\"P1_Idealistic_Budgeting\", env=env)\n","eps = 1e-6\n","\n","# Decision vars\n","x = m.addVars(F, name=\"x\", lb=0.0)                      # added total slots at existing fac\n","a = m.addVars(F, name=\"a\", lb=0.0)                      # 0–5 portion within x\n","y = m.addVars(P, TYPES, vtype=GRB.BINARY, name=\"y\")     # build type at site\n","s = m.addVars(P, TYPES, lb=0.0, name=\"s\")               # 0–5 at new site/type\n","\n","# indicator for >=100% expansion at facility f (x_f >= current capacity)\n","b100 = m.addVars(F, vtype=GRB.BINARY, name=\"b100\")\n","\n","# Objective (min cost)\n","obj_build = gp.quicksum(c_build[t] * y[p,t] for p in P for t in TYPES)\n","\n","# corrected expansion cost: pay once per facility if x_f >= current capacity\n","obj_exp_fixed = gp.quicksum(\n","    b100[f] * (baseline_cost + 200.0 * float(Cnow_f.get(f,0.0)))\n","    for f in F\n",")\n","\n","obj_equip = 100.0 * (gp.quicksum(s[p,t] for p in P for t in TYPES) + gp.quicksum(a[f] for f in F))\n","m.setObjective(obj_build + obj_exp_fixed + obj_equip, GRB.MINIMIZE)\n","\n","# Linking / bounds\n","for f in F:\n","    m.addConstr(x[f] <= xmax_f[f], name=f\"bound_x_{f}\")\n","    m.addConstr(a[f] <= x[f],      name=f\"bound_a_le_x_{f}\")\n","\n","    cnow = float(Cnow_f.get(f, 0.0))\n","    if cnow > 0.0:\n","        # if b100=0 then x <= cnow - eps; if x >= cnow then must set b100=1\n","        m.addConstr(x[f] <= (cnow - eps) + xmax_f[f]*b100[f], name=f\"trigger_up_{f}\")\n","        # if b100=1 then x >= cnow\n","        m.addConstr(x[f] >= cnow * b100[f], name=f\"trigger_lo_{f}\")\n","    else:\n","        # no current capacity -> do not charge the step cost\n","        m.addConstr(b100[f] == 0, name=f\"trigger_zero_{f}\")\n","\n","for p in P:\n","    for t in TYPES:\n","        m.addConstr(s[p,t] <= K_0_5[t] * y[p,t], name=f\"bound_s_le_K05y_{p}_{t}\")\n","\n","# at most one facility type per site\n","for p in P:\n","    m.addConstr(gp.quicksum(y[p,t] for t in TYPES) <= 1, name=f\"C_one_type_per_site_{p}\")\n","\n","# Coverage — C1 (0–12 total)\n","for z in needy_12:\n","    lhs_12 = gp.quicksum(K_total[t] * y[p,t] for p in Pz[z] for t in TYPES) + gp.quicksum(x[f] for f in Fz[z])\n","    rhs_12 = deficit12_by_zip[z]\n","    m.addConstr(lhs_12 >= rhs_12, name=f\"C1_cover12_{z}\")\n","\n","# Coverage — C2 (0–5 share)\n","for z in needy_05:\n","    lhs_05 = gp.quicksum(s[p,t] for p in Pz[z] for t in TYPES) + gp.quicksum(a[f] for f in Fz[z])\n","    rhs_05 = deficit05_by_zip[z]\n","    m.addConstr(lhs_05 >= rhs_05, name=f\"C2_cover05_{z}\")\n","\n","m.update()\n","print(f\"Model size: {m.NumVars} vars, {m.NumConstrs} rows\")\n","\n","# ======================================================\n","# Step 7 — solve\n","# ======================================================\n","m.Params.MIPGap    = 1e-3\n","m.Params.TimeLimit = 600\n","m.optimize()\n","\n","# If infeasible, write IIS to OUTPUT_PATH\n","status_map = {\n","    GRB.OPTIMAL: \"OPTIMAL\",\n","    GRB.TIME_LIMIT: \"TIME_LIMIT\",\n","    GRB.SUBOPTIMAL: \"SUBOPTIMAL\",\n","    GRB.INTERRUPTED: \"INTERRUPTED\",\n","    GRB.INFEASIBLE: \"INFEASIBLE\",\n","    GRB.INF_OR_UNBD: \"INF_OR_UNBD\",\n","    GRB.UNBOUNDED: \"UNBOUNDED\",\n","}\n","status_txt = status_map.get(m.Status, f\"STATUS_{m.Status}\")\n","\n","if m.Status == GRB.INFEASIBLE:\n","    try:\n","        m.computeIIS()\n","        iis_path = os.path.join(OUTPUT_PATH, \"p1_budgeting.iis\")\n","        m.write(iis_path)\n","        print(\"IIS written to:\", iis_path)\n","    except Exception as _:\n","        pass\n","\n","obj_val = m.objVal if m.SolCount > 0 else None\n","\n","# ===============================================\n","# Step 8 — extract solution + coverage validation\n","# ===============================================\n","# expansions\n","exp_rows = []\n","if m.SolCount > 0:\n","    for f_id in F:\n","        xv = x[f_id].X\n","        av = a[f_id].X\n","        bv = int(round(b100[f_id].X))\n","        if xv > 1e-6:\n","            fixed_cost = (baseline_cost + 200.0 * float(Cnow_f.get(f_id,0.0))) if bv == 1 else 0.0\n","            exp_rows.append({\n","                \"facility_id\": f_id,\n","                \"zipcode\": z_of_f[f_id],\n","                \"expansion_slots\": float(xv),\n","                \"expansion_0_5\": float(av),\n","                \"trigger_ge_100pct\": bv,\n","                \"cost_expansion_fixed\": fixed_cost,\n","                \"cost_equip_0_5_exp\": float(av) * c_equip,\n","            })\n","exp_df = pd.DataFrame(exp_rows)\n","\n","# new builds\n","new_rows = []\n","if m.SolCount > 0:\n","    for p in P:\n","        for t in TYPES:\n","            yv = y[p,t].X\n","            sv = s[p,t].X\n","            if yv > 0.5:\n","                new_rows.append({\n","                    \"location_id\": p,\n","                    \"zipcode\": z_of_p[p],\n","                    \"type\": t,\n","                    \"built\": int(round(yv)),\n","                    \"added_slots_total\": K_total[t] * int(round(yv)),\n","                    \"added_slots_0_5_designated\": float(sv),\n","                    \"cost_build\": c_build[t] * int(round(yv)),\n","                    \"cost_equip_0_5_new\": float(sv) * c_equip,\n","                })\n","new_df = pd.DataFrame(new_rows)\n","\n","# total added per zip (keep as Series)\n","added_total_zip = pd.Series(0.0, index=pd.Index(Z, name=\"zipcode\"))\n","if not exp_df.empty:\n","    added_total_zip = added_total_zip.add(exp_df.groupby(\"zipcode\")[\"expansion_slots\"].sum(), fill_value=0.0)\n","if not new_df.empty:\n","    added_total_zip = added_total_zip.add(new_df.groupby(\"zipcode\")[\"added_slots_total\"].sum(), fill_value=0.0)\n","\n","# total 0–5 added per zip\n","added_05_zip = pd.Series(0.0, index=pd.Index(Z, name=\"zipcode\"))\n","if not exp_df.empty:\n","    added_05_zip = added_05_zip.add(exp_df.groupby(\"zipcode\")[\"expansion_0_5\"].sum(), fill_value=0.0)\n","if not new_df.empty:\n","    added_05_zip = added_05_zip.add(new_df.groupby(\"zipcode\")[\"added_slots_0_5_designated\"].sum(), fill_value=0.0)\n","\n","# coverage check — C1 & C2\n","rows = []\n","for z in Z:\n","    target12  = float(Target_slots.get(z, 0.0))\n","    current12 = float(Cnow_tot.get(z, 0.0))\n","    added12   = float(added_total_zip.get(z, 0.0))\n","\n","    target05  = float(tau_05 * N0_5_series.loc[z])\n","    current05 = float(Cnow_05_series.loc[z])\n","    added05   = float(added_05_zip.get(z, 0.0))\n","\n","    rows.append({\n","        \"zipcode\": z,\n","        \"current_slots_0_12\": current12,\n","        \"added_slots_0_12\": added12,\n","        \"target_slots_0_12\": target12,\n","        \"meets_C1_total\": (current12 + added12 + 1e-6) >= target12,\n","        \"current_slots_0_5\": current05,\n","        \"added_slots_0_5\": added05,\n","        \"target_slots_0_5\": target05,\n","        \"meets_C2_0_5\": (current05 + added05 + 1e-6) >= target05,\n","    })\n","cover_df = pd.DataFrame(rows)\n","\n","# =========================================\n","# Step 9 — write CSVs + print summary stats\n","# =========================================\n","exp_out  = os.path.join(OUTPUT_PATH, \"p1_sol_expansions.csv\")\n","new_out  = os.path.join(OUTPUT_PATH, \"p1_sol_newbuild.csv\")\n","cov_out  = os.path.join(OUTPUT_PATH, \"p1_sol_zip_coverage_check.csv\")\n","\n","if not exp_df.empty:\n","    exp_df.to_csv(exp_out, index=False)\n","if not new_df.empty:\n","    new_df.to_csv(new_out, index=False)\n","cover_df.to_csv(cov_out, index=False)\n","\n","print(\"\\n=== P1 Solution Summary ===\")\n","print(\"Status:\", status_txt)\n","print(\"Objective (total $):\", f\"{obj_val:,.0f}\" if obj_val is not None else None)\n","print(\"# facilities expanded:\", 0 if exp_df.empty else len(exp_df))\n","print(\"# new facilities built:\", 0 if new_df.empty else len(new_df))\n","print(\"ZIPs meeting C1 (0–12):\", int(cover_df['meets_C1_total'].sum()), \"/\", len(cover_df))\n","print(\"ZIPs meeting C2 (0–5): \", int(cover_df['meets_C2_0_5'].sum()), \"/\", len(cover_df))\n","\n","if obj_val is not None:\n","    exp_fixed_cost = float(exp_df['cost_expansion_fixed'].sum()) if 'cost_expansion_fixed' in exp_df.columns else 0.0\n","    build_cost = float(new_df['cost_build'].sum()) if not new_df.empty else 0.0\n","    equip_cost = (\n","        float(exp_df['cost_equip_0_5_exp'].sum()) if 'cost_equip_0_5_exp' in exp_df.columns else 0.0\n","    ) + (\n","        float(new_df['cost_equip_0_5_new'].sum()) if 'cost_equip_0_5_new' in new_df.columns else 0.0\n","    )\n","    print(f\"Cost breakdown — build: ${build_cost:,.0f}, expansion_fixed: ${exp_fixed_cost:,.0f}, equipment: ${equip_cost:,.0f}\")\n","\n","print(\"\\nWrote:\")\n","if not exp_df.empty: print(\" -\", exp_out)\n","if not new_df.empty: print(\" -\", new_out)\n","print(\" -\", cov_out)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wJQKcafQLidR","executionInfo":{"status":"ok","timestamp":1762201895174,"user_tz":300,"elapsed":46292,"user":{"displayName":"Victor Tenneroni","userId":"03459946062708176020"}},"outputId":"fd201a96-2193-4bd1-a16d-40ab4338acbf"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","✓ Google Drive mounted.\n","DATA_PATH: /content/drive/MyDrive/IEORE4004 Optimization Models and Methods/IEOR4404_Proj1/data/\n","OUTPUT_PATH: /content/drive/MyDrive/IEORE4004 Optimization Models and Methods/IEOR4404_Proj1/cleaned_data/\n","✓ Loaded cleaned inputs. \n"," master: (1375, 14) \n"," fac   : (14435, 5) \n"," locs  : (137500, 4) \n"," zipage: (1604, 5)\n","Set parameter WLSAccessID\n","Set parameter WLSSecret\n","Set parameter LicenseID to value 2726201\n","Academic license 2726201 - for non-commercial use only - registered to hd___@columbia.edu\n","✓ Gurobi WLS environment created.\n","ZIPs with need — C1: 1229, C2: 1237, union: 1299; kept sites: 129900\n","Sites after per-ZIP cap (20): 25980\n","C1 impossible ZIPs: 1 ['11219']\n","C2 impossible ZIPs: 3 ['10950', '11219', '11230']\n","Model size: 199185 vars, 164121 rows\n","Set parameter MIPGap to value 0.001\n","Set parameter TimeLimit to value 600\n","Gurobi Optimizer version 12.0.3 build v12.0.3rc0 (linux64 - \"Ubuntu 22.04.4 LTS\")\n","\n","CPU model: AMD EPYC 7B12, instruction set [SSE2|AVX|AVX2]\n","Thread count: 1 physical cores, 2 logical processors, using up to 2 threads\n","\n","Non-default parameters:\n","TimeLimit  600\n","MIPGap  0.001\n","\n","Academic license 2726201 - for non-commercial use only - registered to hd___@columbia.edu\n","Optimize a model with 164121 rows, 199185 columns and 509327 nonzeros\n","Model fingerprint: 0x4b4fc61e\n","Variable types: 106810 continuous, 92375 integer (92375 binary)\n","Coefficient statistics:\n","  Matrix range     [1e+00, 9e+02]\n","  Objective range  [1e+02, 2e+05]\n","  Bounds range     [1e+00, 1e+00]\n","  RHS range        [4e-02, 9e+03]\n","Presolve removed 138404 rows and 156388 columns (presolve time = 9s)...\n","Presolve removed 138404 rows and 156388 columns\n","Presolve time: 8.61s\n","Presolved: 25717 rows, 42797 columns, 88066 nonzeros\n","Variable types: 21439 continuous, 21358 integer (21358 binary)\n","\n","Root simplex log...\n","\n","Iteration    Objective       Primal Inf.    Dual Inf.      Time\n","       0    1.1310669e+08   4.606873e+04   0.000000e+00      9s\n","   17775    1.9405915e+08   0.000000e+00   0.000000e+00      9s\n","\n","Root relaxation: objective 1.940591e+08, 17775 iterations, 0.15 seconds (0.10 work units)\n","\n","    Nodes    |    Current Node    |     Objective Bounds      |     Work\n"," Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n","\n","     0     0 1.9406e+08    0  122          - 1.9406e+08      -     -    9s\n","H    0     0                    2.013529e+08 1.9406e+08  3.62%     -    9s\n","H    0     0                    2.006729e+08 1.9406e+08  3.30%     -    9s\n","H    0     0                    2.005051e+08 1.9406e+08  3.21%     -    9s\n","     0     0 1.9538e+08    0  161 2.0051e+08 1.9538e+08  2.56%     -    9s\n","     0     0 1.9720e+08    0  150 2.0051e+08 1.9720e+08  1.65%     -   10s\n","     0     0 1.9783e+08    0   75 2.0051e+08 1.9783e+08  1.33%     -   10s\n","     0     0 1.9799e+08    0   53 2.0051e+08 1.9799e+08  1.26%     -   10s\n","     0     0 1.9803e+08    0   43 2.0051e+08 1.9803e+08  1.23%     -   10s\n","     0     0 1.9803e+08    0   35 2.0051e+08 1.9803e+08  1.23%     -   10s\n","     0     0 1.9804e+08    0   35 2.0051e+08 1.9804e+08  1.23%     -   10s\n","     0     0 1.9804e+08    0   35 2.0051e+08 1.9804e+08  1.23%     -   10s\n","     0     0 1.9804e+08    0   23 2.0051e+08 1.9804e+08  1.23%     -   10s\n","H    0     0                    1.987431e+08 1.9804e+08  0.36%     -   10s\n","H    0     0                    1.982473e+08 1.9804e+08  0.11%     -   10s\n","     0     0 1.9804e+08    0   23 1.9825e+08 1.9804e+08  0.11%     -   10s\n","     0     0 1.9804e+08    0   25 1.9825e+08 1.9804e+08  0.11%     -   11s\n","H    0     0                    1.981899e+08 1.9804e+08  0.08%     -   11s\n","\n","Cutting planes:\n","  Gomory: 68\n","  Cover: 17\n","  MIR: 156\n","  StrongCG: 22\n","  Flow cover: 76\n","  GUB cover: 5\n","  Network: 2\n","  RLT: 12\n","\n","Explored 1 nodes (20181 simplex iterations) in 11.63 seconds (6.80 work units)\n","Thread count was 2 (of 2 available processors)\n","\n","Solution count 7: 1.9819e+08 1.9819e+08 1.98247e+08 ... 2.01353e+08\n","\n","Optimal solution found (tolerance 1.00e-03)\n","Warning: max constraint violation (9.0000e-06) exceeds tolerance\n","Best objective 1.981898707212e+08, best bound 1.980368259293e+08, gap 0.0772%\n","\n","=== P1 Solution Summary ===\n","Status: OPTIMAL\n","Objective (total $): 198,189,871\n","# facilities expanded: 14403\n","# new facilities built: 1468\n","ZIPs meeting C1 (0–12): 1372 / 1375\n","ZIPs meeting C2 (0–5):  1365 / 1375\n","Cost breakdown — build: $142,960,000, expansion_fixed: $2,816,400, equipment: $52,413,471\n","\n","Wrote:\n"," - /content/drive/MyDrive/IEORE4004 Optimization Models and Methods/IEOR4404_Proj1/cleaned_data/p1_sol_expansions.csv\n"," - /content/drive/MyDrive/IEORE4004 Optimization Models and Methods/IEOR4404_Proj1/cleaned_data/p1_sol_newbuild.csv\n"," - /content/drive/MyDrive/IEORE4004 Optimization Models and Methods/IEOR4404_Proj1/cleaned_data/p1_sol_zip_coverage_check.csv\n"]}]},{"cell_type":"markdown","source":["# Part 2"],"metadata":{"id":"Yr6UTwHYb_4A"}},{"cell_type":"code","source":["\"\"\"\n","Part 2 - BATCHED SOLUTION WITH RETRY LOGIC\n","Solves zipcodes in batches, then retries failed batches in smaller chunks\n","v4: custom batch sizes\n","\"\"\"\n","\n","import math\n","import pandas as pd\n","import numpy as np\n","from itertools import combinations\n","import os\n","import gurobipy as gp\n","from gurobipy import GRB\n","\n","# WLS license\n","params = {\n","    \"WLSACCESSID\": \"b92cfff8-0279-4652-9cb7-3e6bcdb967cd\",\n","    \"WLSSECRET\":   \"e6220bd1-2657-40f8-ba01-6cebcb97db7f\",\n","    \"LICENSEID\":   2726201,\n","}\n","env = gp.Env(params=params)\n","\n","# ========== PARAMETERS ==========\n","MIN_DISTANCE_MILES = 0.06\n","EXPANSION_CAP_FRAC = 0.40\n","LOCATIONS_PER_ZIP_MAX = 50\n","MAX_ZIPS_TO_CONSIDER = 1400\n","LOCATIONS_PER_ZIP_MIN = 3\n","\n","TIME_LIMIT_SECONDS = 600\n","MAX_FACILITIES_PER_ZIP = 30\n","\n","SEGMENT_BREAKPOINTS = [0.10, 0.15, 0.20, 0.30, 0.40]\n","SEGMENT_COSTS = [200, 400, 1000, 2000, 3000]\n","BASE_COST = 20000\n","\n","NEW_FACILITY_SIZES = {\n","    'small': {'max_slots_0_5': 80, 'cost': 65000, 'max_slots_allages': 100},\n","    'medium': {'max_slots_0_5': 160, 'cost': 95000, 'max_slots_allages': 200},\n","    'large': {'max_slots_0_5': 320, 'cost': 115000, 'max_slots_allages': 400}\n","}\n","\n","EQUIP_COST_PER_SLOT_0_5 = 100\n","\n","def haversine_miles(lat1, lon1, lat2, lon2):\n","    R = 3958.8\n","    phi1, phi2 = math.radians(lat1), math.radians(lat2)\n","    dphi = math.radians(lat2 - lat1)\n","    dlambda = math.radians(lon2 - lon1)\n","    a = math.sin(dphi/2)**2 + math.cos(phi1)*math.cos(phi2)*math.sin(dlambda/2)**2\n","    return 2*R*math.asin(math.sqrt(a))\n","\n","def piecewise_expansion_cost(nf, x):\n","    if nf == 0 or x <= 0:\n","        return 0.0\n","\n","    frac = x / nf\n","    cumulative_cost = 0\n","    remaining_x = x\n","\n","    for i in range(len(SEGMENT_BREAKPOINTS)):\n","        if frac <= SEGMENT_BREAKPOINTS[i]:\n","            marginal_cost = BASE_COST / nf + SEGMENT_COSTS[i]\n","            cumulative_cost += marginal_cost * remaining_x\n","            return cumulative_cost\n","        else:\n","            if i == 0:\n","                segment_slots = int(nf * SEGMENT_BREAKPOINTS[i])\n","            else:\n","                segment_slots = int(nf * SEGMENT_BREAKPOINTS[i]) - int(nf * SEGMENT_BREAKPOINTS[i-1])\n","\n","            marginal_cost = BASE_COST / nf + SEGMENT_COSTS[i]\n","            cumulative_cost += marginal_cost * segment_slots\n","            remaining_x -= segment_slots\n","\n","    return 1e9\n","\n","def solve_batch(batch_zips, batch_name, all_expansions, all_newbuilds, all_verification, fac_index, pl_index):\n","    \"\"\"Solve a single batch of zipcodes\"\"\"\n","\n","    # Select locations for this batch\n","    selected_locations = []\n","    selected_ids = set()\n","\n","    for _, zip_row in batch_zips.iterrows():\n","        zipcode = str(zip_row['zipcode'])\n","        n_to_select = int(zip_row['min_locations_needed'])\n","\n","        candidates = locs[locs['zipcode'] == zipcode].copy()\n","\n","        if candidates.empty:\n","            continue\n","\n","        existing_in_zip = fac[fac['zipcode'] == zipcode]\n","\n","        # PRE-FILTER\n","        valid_candidates = []\n","        for _, loc_row in candidates.iterrows():\n","            loc_lat = loc_row['latitude']\n","            loc_lon = loc_row['longitude']\n","\n","            too_close = False\n","            for _, fac_row in existing_in_zip.iterrows():\n","                dist = haversine_miles(loc_lat, loc_lon, fac_row['latitude'], fac_row['longitude'])\n","                if dist < MIN_DISTANCE_MILES:\n","                    too_close = True\n","                    break\n","\n","            if not too_close:\n","                valid_candidates.append(loc_row)\n","\n","        candidates = pd.DataFrame(valid_candidates)\n","\n","        if not candidates.empty:\n","            if not existing_in_zip.empty:\n","                mean_lat = existing_in_zip['latitude'].mean()\n","                mean_lon = existing_in_zip['longitude'].mean()\n","\n","                candidates['dist_to_center'] = candidates.apply(\n","                    lambda row: haversine_miles(row['latitude'], row['longitude'], mean_lat, mean_lon),\n","                    axis=1\n","                )\n","                candidates = candidates.sort_values('dist_to_center', ascending=False)\n","\n","            selected_count = 0\n","            for _, loc_row in candidates.iterrows():\n","                if selected_count >= n_to_select:\n","                    break\n","\n","                loc_id = loc_row['location_id']\n","                if loc_id not in selected_ids:\n","                    loc_lat = loc_row['latitude']\n","                    loc_lon = loc_row['longitude']\n","\n","                    too_close_to_selected = False\n","                    for already_selected in selected_locations:\n","                        if str(already_selected['zipcode']) == zipcode:\n","                            dist = haversine_miles(loc_lat, loc_lon,\n","                                                 already_selected['latitude'],\n","                                                 already_selected['longitude'])\n","                            if dist < MIN_DISTANCE_MILES:\n","                                too_close_to_selected = True\n","                                break\n","\n","                    if not too_close_to_selected:\n","                        selected_locations.append(loc_row)\n","                        selected_ids.add(loc_id)\n","                        selected_count += 1\n","\n","    selected_df = pd.DataFrame(selected_locations)\n","\n","    if selected_df.empty:\n","        print(f\"  No locations selected for {batch_name}, skipping...\")\n","        return False\n","\n","    print(f\"  Selected {len(selected_df)} locations\")\n","\n","    # Setup optimization\n","    selected_zipcodes = set(selected_df['zipcode'].astype(str))\n","    selected_df['location_id'] = selected_df['location_id'].astype(str)\n","    pl_index = selected_df.set_index('location_id', drop=False) # Update pl_index for this batch\n","    selected_locs_list = list(pl_index.index)\n","\n","    facilities_stage2 = []\n","    for z in selected_zipcodes:\n","        zip_facilities = fac[fac['zipcode'] == z].copy()\n","\n","        if zip_facilities.empty:\n","            continue\n","\n","        zip_facilities = zip_facilities.sort_values('capacity', ascending=False)\n","\n","        for _, row in zip_facilities.head(MAX_FACILITIES_PER_ZIP).iterrows():\n","            facility_id = str(row['facility_id'])\n","            try:\n","                current_cap = int(row['capacity']) if 'capacity' in row else 0\n","                if current_cap > 0:\n","                    facilities_stage2.append(facility_id)\n","            except:\n","                pass\n","\n","    print(f\"  Problem size: {len(facilities_stage2)} facilities, {len(selected_locs_list)} locations\")\n","\n","    # fac_index = fac.set_index('facility_id', drop=False) # Already done outside the function\n","    zipdf_index = master.set_index('zipcode', drop=False)\n","\n","    current_capacity = {}\n","    for f in facilities_stage2:\n","        try:\n","            if str(f).isdigit() and int(f) in fac_index.index:\n","                nf = int(fac_index.at[int(f), 'capacity'])\n","            elif f in fac_index.index:\n","                nf = int(fac_index.at[f, 'capacity'])\n","            else:\n","                nf = 0\n","        except:\n","            nf = 0\n","        current_capacity[f] = nf\n","\n","    # Build model\n","    m = gp.Model(batch_name, env=env)\n","    m.setParam('TimeLimit', TIME_LIMIT_SECONDS)\n","    m.setParam('OutputFlag', 0)\n","\n","    x = {}\n","    for f in facilities_stage2:\n","        nf = current_capacity[f]\n","        max_exp = int(nf * EXPANSION_CAP_FRAC) if nf > 0 else 0\n","        x[f] = m.addVar(lb=0, ub=max_exp, vtype=GRB.INTEGER, name=f\"x_{f}\")\n","\n","    y = {}\n","    for j in selected_locs_list:\n","        for s in NEW_FACILITY_SIZES.keys():\n","            y[j,s] = m.addVar(vtype=GRB.BINARY, name=f\"y_{j}_{s}\")\n","\n","    anybuild = {}\n","    for j in selected_locs_list:\n","        anybuild[j] = m.addVar(vtype=GRB.BINARY, name=f\"anybuild_{j}\")\n","\n","    m.update()\n","\n","    # Piecewise expansion costs\n","    for f in facilities_stage2:\n","        nf = current_capacity[f]\n","        if nf == 0:\n","            continue\n","\n","        max_exp_slots = int(nf * EXPANSION_CAP_FRAC)\n","\n","        points = [0]\n","        values = [0]\n","\n","        for i, bp in enumerate(SEGMENT_BREAKPOINTS):\n","            if bp <= EXPANSION_CAP_FRAC:\n","                bp_slots = int(nf * bp)\n","                if bp_slots > points[-1] and bp_slots <= max_exp_slots:\n","                    cum_cost = 0\n","                    for j in range(i + 1):\n","                        if j == 0:\n","                            seg_start = 0\n","                        else:\n","                            seg_start = int(nf * SEGMENT_BREAKPOINTS[j-1])\n","\n","                        seg_end = min(int(nf * SEGMENT_BREAKPOINTS[j]), bp_slots)\n","\n","                        if seg_end > seg_start:\n","                            marginal = BASE_COST/nf + SEGMENT_COSTS[j]\n","                            cum_cost += marginal * (seg_end - seg_start)\n","\n","                    points.append(bp_slots)\n","                    values.append(cum_cost)\n","\n","        if points[-1] < max_exp_slots:\n","            seg_idx = len(SEGMENT_COSTS) - 1\n","            cum_cost = values[-1]\n","            marginal = BASE_COST/nf + SEGMENT_COSTS[seg_idx]\n","            cum_cost += marginal * (max_exp_slots - points[-1])\n","            points.append(max_exp_slots)\n","            values.append(cum_cost)\n","\n","        if len(points) > 1:\n","            m.setPWLObj(x[f], points, values)\n","\n","    m.update()\n","\n","    # Constraints\n","    for j in selected_locs_list:\n","        m.addConstr(gp.quicksum(y[j,s] for s in NEW_FACILITY_SIZES.keys()) <= 1, name=f\"one_size_{j}\")\n","\n","    for j in selected_locs_list:\n","        m.addConstr(anybuild[j] == gp.quicksum(y[j,s] for s in NEW_FACILITY_SIZES.keys()), name=f\"link_{j}\")\n","\n","    # Distance constraints\n","    for z in selected_zipcodes:\n","        existing_in_z = [f for f in facilities_stage2\n","                         if str(f).isdigit() and int(f) in fac_index.index\n","                         and str(fac_index.at[int(f), 'zipcode']) == z]\n","        new_in_z = [j for j in selected_locs_list if str(pl_index.at[j, 'zipcode']) == z]\n","\n","        for f in existing_in_z:\n","            try:\n","                lat_f = float(fac_index.at[int(f), 'latitude'])\n","                lon_f = float(fac_index.at[int(f), 'longitude'])\n","            except:\n","                continue\n","\n","            for j in new_in_z:\n","                try:\n","                    lat_j = float(pl_index.at[j, 'latitude'])\n","                    lon_j = float(pl_index.at[j, 'longitude'])\n","                except:\n","                    continue\n","\n","                dist = haversine_miles(lat_f, lon_f, lat_j, lon_j)\n","                if dist < MIN_DISTANCE_MILES:\n","                    m.addConstr(anybuild[j] == 0, name=f\"dist_{f}_{j}\")\n","\n","        for j1, j2 in combinations(new_in_z, 2):\n","            try:\n","                lat1 = float(pl_index.at[j1, 'latitude'])\n","                lon1 = float(pl_index.at[j1, 'longitude'])\n","                lat2 = float(pl_index.at[j2, 'latitude'])\n","                lon2 = float(pl_index.at[j2, 'longitude'])\n","\n","                dist = haversine_miles(lat1, lon1, lat2, lon2)\n","                if dist < MIN_DISTANCE_MILES:\n","                    m.addConstr(anybuild[j1] + anybuild[j2] <= 1, name=f\"dist_{j1}_{j2}\")\n","            except:\n","                continue\n","\n","\n","    # Coverage constraints\n","    for z in selected_zipcodes:\n","        if z not in zipdf_index.index:\n","            continue\n","\n","        desert_threshold = float(zipdf_index.at[z, 'desert_threshold'])\n","        children_0_5 = float(zipdf_index.at[z, 'pop_0_5'])\n","\n","        existing_in_z = [f for f in facilities_stage2\n","                         if str(f).isdigit() and int(f) in fac_index.index\n","                         and str(fac_index.at[int(f), 'zipcode']) == z]\n","\n","        current_total = sum(current_capacity.get(f, 0) for f in existing_in_z)\n","        expansion_slots = gp.quicksum(x[f] for f in existing_in_z)\n","\n","        new_in_z = [j for j in selected_locs_list if str(pl_index.at[j, 'zipcode']) == z]\n","        new_slots_total = gp.quicksum(\n","            NEW_FACILITY_SIZES[s]['max_slots_allages'] * y[j,s]\n","            for j in new_in_z for s in NEW_FACILITY_SIZES.keys()\n","        )\n","        new_slots_0_5 = gp.quicksum(\n","            NEW_FACILITY_SIZES[s]['max_slots_0_5'] * y[j,s]\n","            for j in new_in_z for s in NEW_FACILITY_SIZES.keys()\n","        )\n","\n","        total_slots = current_total + expansion_slots + new_slots_total\n","\n","        m.addConstr(total_slots >= desert_threshold, name=f\"desert_{z}\")\n","\n","        min_slots_0_5 = children_0_5 * (2.0/3.0)\n","        current_0_5_approx = current_total * 0.8 # Approximation based on overall facility data\n","        total_0_5_capacity = current_0_5_approx + expansion_slots * 0.8 + new_slots_0_5 # Approximation\n","        m.addConstr(total_0_5_capacity >= min_slots_0_5, name=f\"min_0_5_{z}\")\n","\n","\n","    # Objective\n","    new_build_cost = gp.quicksum(\n","        NEW_FACILITY_SIZES[s]['cost'] * y[j,s]\n","        for j in selected_locs_list for s in NEW_FACILITY_SIZES.keys()\n","    )\n","\n","    new_equip_cost = gp.quicksum(\n","        EQUIP_COST_PER_SLOT_0_5 * NEW_FACILITY_SIZES[s]['max_slots_0_5'] * y[j,s]\n","        for j in selected_locs_list for s in NEW_FACILITY_SIZES.keys()\n","    )\n","\n","    m.setObjective(new_build_cost + new_equip_cost, GRB.MINIMIZE)\n","\n","    # Solve\n","    print(f\"  Solving {batch_name}...\")\n","    m.optimize()\n","\n","    if m.status == GRB.INFEASIBLE:\n","        print(f\"  ❌ {batch_name} INFEASIBLE\")\n","        return False\n","    elif m.status in [GRB.OPTIMAL, GRB.TIME_LIMIT]:\n","        print(f\"  ✓ {batch_name}: ${m.objVal:,.2f}\")\n","\n","        # Extract results\n","        for f in facilities_stage2:\n","            val = int(round(x[f].X)) if x[f].X is not None else 0\n","            if val > 0:\n","                nf = current_capacity[f]\n","                cost = piecewise_expansion_cost(nf, val)\n","                # Get lat/lon for expansion\n","                fac_lat = float(fac_index.at[int(f), 'latitude']) if int(f) in fac_index.index and 'latitude' in fac_index.columns else None\n","                fac_lon = float(fac_index.at[int(f), 'longitude']) if int(f) in fac_index.index and 'longitude' in fac_index.columns else None\n","\n","                all_expansions.append({\n","                    'batch': batch_name,\n","                    'facility_id': f,\n","                    'zipcode': str(fac_index.at[int(f), 'zipcode']) if int(f) in fac_index.index else None,\n","                    'latitude': fac_lat,\n","                    'longitude': fac_lon,\n","                    'added_slots': val,\n","                    'cost': float(cost)\n","                })\n","\n","        for j in selected_locs_list:\n","            for s in NEW_FACILITY_SIZES.keys():\n","                if y[j,s].X is not None and y[j,s].X > 0.5:\n","                    meta = NEW_FACILITY_SIZES[s]\n","                    # Get lat/lon for new build\n","                    loc_lat = float(pl_index.at[j, 'latitude']) if j in pl_index.index and 'latitude' in pl_index.columns else None\n","                    loc_lon = float(pl_index.at[j, 'longitude']) if j in pl_index.index and 'longitude' in pl_index.columns else None\n","\n","                    all_newbuilds.append({\n","                        'batch': batch_name,\n","                        'location_id': j,\n","                        'zipcode': str(pl_index.at[j, 'zipcode']) if j in pl_index.index else None,\n","                        'latitude': loc_lat,\n","                        'longitude': loc_lon,\n","                        'size': s,\n","                        'added_slots': meta['max_slots_allages'],\n","                        'build_cost': float(meta['cost']),\n","                        'equip_cost_0_5': float(EQUIP_COST_PER_SLOT_0_5 * meta['max_slots_0_5'])\n","                    })\n","\n","        for z in selected_zipcodes:\n","            if z not in zipdf_index.index:\n","                continue\n","\n","            threshold = float(zipdf_index.at[z, 'desert_threshold'])\n","            current_existing = float(zipdf_index.at[z, 'total_existing_slots'])\n","\n","            existing_in_z = [f for f in facilities_stage2\n","                         if str(f).isdigit() and int(f) in fac_index.index\n","                         and str(fac_index.at[int(f), 'zipcode']) == z]\n","            added_exp = sum(int(round(x[f].X)) for f in existing_in_z if x[f].X is not None)\n","\n","            new_in_z = [j for j in selected_locs_list if str(pl_index.at[j, 'zipcode']) == z]\n","            added_new = sum(\n","                NEW_FACILITY_SIZES[s]['max_slots_allages']\n","                for j in new_in_z for s in NEW_FACILITY_SIZES.keys()\n","                if y[j,s].X is not None and y[j,s].X > 0.5\n","            )\n","\n","            total = current_existing + added_exp + added_new\n","            meets = total >= threshold - 1e-6\n","\n","            all_verification.append({\n","                'batch': batch_name,\n","                'zipcode': z,\n","                'threshold': threshold,\n","                'current': current_existing,\n","                'added_exp': added_exp,\n","                'added_new': added_new,\n","                'total': total,\n","                'meets': meets\n","            })\n","\n","        return True\n","\n","    return False\n","\n","print(\"Loading data...\")\n","\n","try:\n","    master = pd.read_csv(os.path.join(OUTPUT_PATH, 'zipcode_master.csv'), dtype={'zipcode': str})\n","    fac = pd.read_csv(os.path.join(OUTPUT_PATH, 'facilities_clean.csv'))\n","    locs = pd.read_csv(os.path.join(OUTPUT_PATH, 'locations_clean.csv'))\n","except FileNotFoundError as e:\n","    print(f\"Error: {e}\")\n","    exit(1)\n","\n","for df in [master, fac, locs]:\n","    if 'zipcode' in df.columns:\n","        df['zipcode'] = df['zipcode'].astype(str).str.zfill(5)\n","\n","# Create index DataFrames for faster lookups\n","fac_index = fac.set_index('facility_id')\n","locs['location_id'] = locs['location_id'].astype(str) # Ensure location_id is string for index\n","pl_index = locs.set_index('location_id')\n","\n","\n","print(f\"Data loaded: {len(master)} zips, {len(fac)} facilities, {len(locs)} locations\")\n","\n","# ========== STAGE 1: IDENTIFY ALL NEEDY ZIPCODES ==========\n","print(\"\\n\" + \"=\"*60)\n","print(\"STAGE 1: Identify needy zipcodes\")\n","print(\"=\"*60)\n","\n","master['need'] = master['desert_threshold'] - master['total_existing_slots']\n","master['need'] = master['need'].clip(lower=0)\n","\n","print(\"\\nCalculating expansion potential per zipcode...\")\n","master['expansion_potential'] = 0.0\n","\n","for idx, row in master.iterrows():\n","    zipcode = str(row['zipcode'])\n","    zip_facs = fac[fac['zipcode'] == zipcode].nlargest(MAX_FACILITIES_PER_ZIP, 'capacity')\n","\n","    if not zip_facs.empty:\n","        total_current = zip_facs['capacity'].sum()\n","        max_expansion = int(total_current * EXPANSION_CAP_FRAC)\n","        master.at[idx, 'expansion_potential'] = max_expansion\n","\n","master['need_after_expansion'] = (master['need'] - master['expansion_potential']).clip(lower=0)\n","\n","LARGE_FACILITY_CAPACITY = 400\n","LARGE_FACILITY_0_5_CAPACITY = 320\n","\n","master['locations_for_0_12'] = np.ceil(master['need_after_expansion'] / LARGE_FACILITY_CAPACITY).astype(int)\n","\n","master['required_0_5'] = master['pop_0_5'] * (2.0/3.0)\n","master['have_0_5_current'] = master['total_existing_slots'] * 0.8 # Approximation\n","master['have_0_5_expansion'] = master['expansion_potential'] * 0.8 # Approximation\n","master['need_0_5_new'] = (master['required_0_5'] - master['have_0_5_current'] - master['have_0_5_expansion']).clip(lower=0)\n","master['locations_for_0_5'] = np.ceil(master['need_0_5_new'] / LARGE_FACILITY_0_5_CAPACITY).astype(int)\n","\n","master['min_locations_needed'] = master[['locations_for_0_12', 'locations_for_0_5']].max(axis=1)\n","master['min_locations_needed'] = master['min_locations_needed'].astype(int)  # NO BUFFER\n","master['min_locations_needed'] = master['min_locations_needed'].clip(lower=LOCATIONS_PER_ZIP_MIN, upper=LOCATIONS_PER_ZIP_MAX)\n","\n","need_sorted = master.sort_values('need_after_expansion', ascending=False)\n","top_zips = need_sorted.head(MAX_ZIPS_TO_CONSIDER)\n","top_zips = top_zips[top_zips['need_after_expansion'] > 0].copy()\n","\n","if top_zips.empty:\n","    print(\"ERROR: No zipcodes with unmet need!\")\n","    exit(1)\n","\n","print(f\"\\nTotal needy zipcodes: {len(top_zips)}\")\n","\n","# Split high-need vs low-need\n","high_need = top_zips.head(500)\n","low_need = top_zips.iloc[500:]\n","\n","# Small batches for high-need areas\n","high_batches = [high_need.iloc[i:i+25] for i in range(0, len(high_need), 25)]\n","\n","# Normal batches for low-need areas\n","low_batches = [low_need.iloc[i:i+100] for i in range(0, len(low_need), 100)]\n","\n","batches = high_batches + low_batches\n","\n","print(f\"High-need batches: {len(high_batches)} (25 zips each)\")\n","print(f\"Low-need batches: {len(low_batches)} (100 zips each)\")\n","print(f\"Total batches: {len(batches)}\")\n","\n","# ========== MAIN BATCH PROCESSING ==========\n","all_expansions = []\n","all_newbuilds = []\n","all_verification = []\n","failed_batches = []\n","\n","for batch_idx, batch_zips in enumerate(batches):\n","    print(f\"\\n{'='*60}\")\n","    print(f\"BATCH {batch_idx+1}/{len(batches)}: {len(batch_zips)} zipcodes\")\n","    print(f\"{'='*60}\")\n","\n","    success = solve_batch(batch_zips, f\"batch_{batch_idx+1}\", all_expansions, all_newbuilds, all_verification, fac_index, pl_index)\n","\n","    if not success:\n","        failed_batches.append((batch_idx, batch_zips))\n","\n","# ========== RETRY FAILED BATCHES ==========\n","if failed_batches:\n","    print(f\"\\n{'='*60}\")\n","    print(f\"RETRYING {len(failed_batches)} FAILED BATCHES (10 zips per chunk)\")\n","    print(f\"{'='*60}\")\n","\n","    for batch_idx, failed_batch in failed_batches:\n","        print(f\"\\nRetrying batch {batch_idx+1}...\")\n","\n","        # Split into 10-zipcode chunks\n","        mini_batches = [failed_batch.iloc[i:i+10] for i in range(0, len(failed_batch), 10)]\n","\n","        for mini_idx, mini_batch in enumerate(mini_batches):\n","            print(f\"\\n--- Chunk {mini_idx+1}/{len(mini_batches)}: {len(mini_batch)} zipcodes ---\")\n","\n","            success = solve_batch(mini_batch, f\"retry_batch_{batch_idx+1}_chunk_{mini_idx+1}\",\n","                                all_expansions, all_newbuilds, all_verification, fac_index, pl_index)\n","\n","            if not success:\n","                print(f\"  Still infeasible: {list(mini_batch['zipcode'])}\")\n","\n","\n","# ========== SAVE RESULTS ==========\n","print(f\"\\n{'='*60}\")\n","print(\"FINAL RESULTS\")\n","print(f\"{'='*60}\")\n","\n","exp_df = pd.DataFrame(all_expansions)\n","new_df = pd.DataFrame(all_newbuilds)\n","ver_df = pd.DataFrame(all_verification)\n","\n","if not exp_df.empty:\n","    exp_df.to_csv(os.path.join(OUTPUT_PATH, 'part2_expansions_final.csv'), index=False)\n","    print(f\"Expansions: {len(exp_df)}\")\n","\n","if not new_df.empty:\n","    new_df.to_csv(os.path.join(OUTPUT_PATH, 'part2_newbuilds_final.csv'), index=False)\n","    print(f\"New builds: {len(new_df)}\")\n","\n","if not ver_df.empty:\n","    ver_df.to_csv(os.path.join(OUTPUT_PATH, 'part2_verification_final.csv'), index=False)\n","    met_count = ver_df['meets'].sum()\n","    total_count = len(ver_df)\n","    print(f\"Zipcodes meeting threshold: {met_count}/{total_count}\")\n","\n","    if not exp_df.empty or not new_df.empty:\n","        total_cost = 0\n","        if not exp_df.empty:\n","            total_cost += exp_df['cost'].sum()\n","        if not new_df.empty:\n","            total_cost += new_df['build_cost'].sum() + new_df['equip_cost_0_5'].sum()\n","        print(f\"Total cost: ${total_cost:,.2f}\")\n","\n","    # Show unsolved zipcodes\n","    if met_count < len(top_zips):\n","        solved_zips = set(ver_df['zipcode'])\n","        unsolved_zips = [z for z in top_zips['zipcode'] if z not in solved_zips]\n","        print(f\"Unsolved zipcodes: {len(unsolved_zips)}\")\n","        if len(unsolved_zips) <= 20:\n","            print(f\"Unsolved: {unsolved_zips}\")\n","\n","\n","print(f\"\\n{'='*60}\")\n","print(\"DONE\")\n","print(f\"{'='*60}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qn_0-PkPLfwe","executionInfo":{"status":"ok","timestamp":1762202004735,"user_tz":300,"elapsed":109542,"user":{"displayName":"Victor Tenneroni","userId":"03459946062708176020"}},"outputId":"c076b6ef-1576-4c64-d14f-bfa8214f1afa"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Set parameter WLSAccessID\n","Set parameter WLSSecret\n","Set parameter LicenseID to value 2726201\n","Academic license 2726201 - for non-commercial use only - registered to hd___@columbia.edu\n","Loading data...\n","Data loaded: 1375 zips, 14435 facilities, 137500 locations\n","\n","============================================================\n","STAGE 1: Identify needy zipcodes\n","============================================================\n","\n","Calculating expansion potential per zipcode...\n","\n","Total needy zipcodes: 1087\n","High-need batches: 20 (25 zips each)\n","Low-need batches: 6 (100 zips each)\n","Total batches: 26\n","\n","============================================================\n","BATCH 1/26: 25 zipcodes\n","============================================================\n","  Selected 277 locations\n","  Problem size: 697 facilities, 277 locations\n","Set parameter TimeLimit to value 600\n","  Solving batch_1...\n","  ❌ batch_1 INFEASIBLE\n","\n","============================================================\n","BATCH 2/26: 25 zipcodes\n","============================================================\n","  Selected 133 locations\n","  Problem size: 633 facilities, 133 locations\n","Set parameter TimeLimit to value 600\n","  Solving batch_2...\n","  ❌ batch_2 INFEASIBLE\n","\n","============================================================\n","BATCH 3/26: 25 zipcodes\n","============================================================\n","  Selected 102 locations\n","  Problem size: 513 facilities, 102 locations\n","Set parameter TimeLimit to value 600\n","  Solving batch_3...\n","  ❌ batch_3 INFEASIBLE\n","\n","============================================================\n","BATCH 4/26: 25 zipcodes\n","============================================================\n","  Selected 76 locations\n","  Problem size: 417 facilities, 76 locations\n","Set parameter TimeLimit to value 600\n","  Solving batch_4...\n","  ❌ batch_4 INFEASIBLE\n","\n","============================================================\n","BATCH 5/26: 25 zipcodes\n","============================================================\n","  Selected 76 locations\n","  Problem size: 350 facilities, 76 locations\n","Set parameter TimeLimit to value 600\n","  Solving batch_5...\n","  ❌ batch_5 INFEASIBLE\n","\n","============================================================\n","BATCH 6/26: 25 zipcodes\n","============================================================\n","  Selected 75 locations\n","  Problem size: 381 facilities, 75 locations\n","Set parameter TimeLimit to value 600\n","  Solving batch_6...\n","  ❌ batch_6 INFEASIBLE\n","\n","============================================================\n","BATCH 7/26: 25 zipcodes\n","============================================================\n","  Selected 75 locations\n","  Problem size: 363 facilities, 75 locations\n","Set parameter TimeLimit to value 600\n","  Solving batch_7...\n","  ❌ batch_7 INFEASIBLE\n","\n","============================================================\n","BATCH 8/26: 25 zipcodes\n","============================================================\n","  Selected 76 locations\n","  Problem size: 299 facilities, 76 locations\n","Set parameter TimeLimit to value 600\n","  Solving batch_8...\n","  ✓ batch_8: $6,883,000.00\n","\n","============================================================\n","BATCH 9/26: 25 zipcodes\n","============================================================\n","  Selected 75 locations\n","  Problem size: 251 facilities, 75 locations\n","Set parameter TimeLimit to value 600\n","  Solving batch_9...\n","  ✓ batch_9: $6,019,000.00\n","\n","============================================================\n","BATCH 10/26: 25 zipcodes\n","============================================================\n","  Selected 76 locations\n","  Problem size: 289 facilities, 76 locations\n","Set parameter TimeLimit to value 600\n","  Solving batch_10...\n","  ❌ batch_10 INFEASIBLE\n","\n","============================================================\n","BATCH 11/26: 25 zipcodes\n","============================================================\n","  Selected 75 locations\n","  Problem size: 203 facilities, 75 locations\n","Set parameter TimeLimit to value 600\n","  Solving batch_11...\n","  ✓ batch_11: $4,078,000.00\n","\n","============================================================\n","BATCH 12/26: 25 zipcodes\n","============================================================\n","  Selected 75 locations\n","  Problem size: 224 facilities, 75 locations\n","Set parameter TimeLimit to value 600\n","  Solving batch_12...\n","  ❌ batch_12 INFEASIBLE\n","\n","============================================================\n","BATCH 13/26: 25 zipcodes\n","============================================================\n","  Selected 75 locations\n","  Problem size: 221 facilities, 75 locations\n","Set parameter TimeLimit to value 600\n","  Solving batch_13...\n","  ✓ batch_13: $4,191,000.00\n","\n","============================================================\n","BATCH 14/26: 25 zipcodes\n","============================================================\n","  Selected 75 locations\n","  Problem size: 98 facilities, 75 locations\n","Set parameter TimeLimit to value 600\n","  Solving batch_14...\n","  ✓ batch_14: $3,675,000.00\n","\n","============================================================\n","BATCH 15/26: 25 zipcodes\n","============================================================\n","  Selected 75 locations\n","  Problem size: 127 facilities, 75 locations\n","Set parameter TimeLimit to value 600\n","  Solving batch_15...\n","  ✓ batch_15: $3,895,000.00\n","\n","============================================================\n","BATCH 16/26: 25 zipcodes\n","============================================================\n","  Selected 75 locations\n","  Problem size: 103 facilities, 75 locations\n","Set parameter TimeLimit to value 600\n","  Solving batch_16...\n","  ❌ batch_16 INFEASIBLE\n","\n","============================================================\n","BATCH 17/26: 25 zipcodes\n","============================================================\n","  Selected 75 locations\n","  Problem size: 115 facilities, 75 locations\n","Set parameter TimeLimit to value 600\n","  Solving batch_17...\n","  ✓ batch_17: $2,811,000.00\n","\n","============================================================\n","BATCH 18/26: 25 zipcodes\n","============================================================\n","  Selected 75 locations\n","  Problem size: 99 facilities, 75 locations\n","Set parameter TimeLimit to value 600\n","  Solving batch_18...\n","  ❌ batch_18 INFEASIBLE\n","\n","============================================================\n","BATCH 19/26: 25 zipcodes\n","============================================================\n","  Selected 75 locations\n","  Problem size: 64 facilities, 75 locations\n","Set parameter TimeLimit to value 600\n","  Solving batch_19...\n","  ✓ batch_19: $2,811,000.00\n","\n","============================================================\n","BATCH 20/26: 25 zipcodes\n","============================================================\n","  Selected 75 locations\n","  Problem size: 68 facilities, 75 locations\n","Set parameter TimeLimit to value 600\n","  Solving batch_20...\n","  ✓ batch_20: $3,030,000.00\n","\n","============================================================\n","BATCH 21/26: 100 zipcodes\n","============================================================\n","  Selected 300 locations\n","  Problem size: 229 facilities, 300 locations\n","Set parameter TimeLimit to value 600\n","  Solving batch_21...\n","  ❌ batch_21 INFEASIBLE\n","\n","============================================================\n","BATCH 22/26: 100 zipcodes\n","============================================================\n","  Selected 300 locations\n","  Problem size: 230 facilities, 300 locations\n","Set parameter TimeLimit to value 600\n","  Solving batch_22...\n","  ❌ batch_22 INFEASIBLE\n","\n","============================================================\n","BATCH 23/26: 100 zipcodes\n","============================================================\n","  Selected 300 locations\n","  Problem size: 219 facilities, 300 locations\n","Set parameter TimeLimit to value 600\n","  Solving batch_23...\n","  ✓ batch_23: $7,562,000.00\n","\n","============================================================\n","BATCH 24/26: 100 zipcodes\n","============================================================\n","  Selected 300 locations\n","  Problem size: 157 facilities, 300 locations\n","Set parameter TimeLimit to value 600\n","  Solving batch_24...\n","  ✓ batch_24: $7,597,000.00\n","\n","============================================================\n","BATCH 25/26: 100 zipcodes\n","============================================================\n","  Selected 300 locations\n","  Problem size: 142 facilities, 300 locations\n","Set parameter TimeLimit to value 600\n","  Solving batch_25...\n","  ✓ batch_25: $7,374,000.00\n","\n","============================================================\n","BATCH 26/26: 87 zipcodes\n","============================================================\n","  Selected 261 locations\n","  Problem size: 160 facilities, 261 locations\n","Set parameter TimeLimit to value 600\n","  Solving batch_26...\n","  ✓ batch_26: $6,389,000.00\n","\n","============================================================\n","RETRYING 13 FAILED BATCHES (10 zips per chunk)\n","============================================================\n","\n","Retrying batch 1...\n","\n","--- Chunk 1/3: 10 zipcodes ---\n","  Selected 157 locations\n","  Problem size: 276 facilities, 157 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_1_chunk_1...\n","  ❌ retry_batch_1_chunk_1 INFEASIBLE\n","  Still infeasible: ['11219', '10977', '11368', '11223', '10950', '11220', '11230', '11204', '11206', '10952']\n","\n","--- Chunk 2/3: 10 zipcodes ---\n","  Selected 85 locations\n","  Problem size: 289 facilities, 85 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_1_chunk_2...\n","  ❌ retry_batch_1_chunk_2 INFEASIBLE\n","  Still infeasible: ['11691', '11208', '11385', '11214', '11432', '11373', '10468', '11213', '11226', '11435']\n","\n","--- Chunk 3/3: 5 zipcodes ---\n","  Selected 35 locations\n","  Problem size: 132 facilities, 35 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_1_chunk_3...\n","  ❌ retry_batch_1_chunk_3 INFEASIBLE\n","  Still infeasible: ['10469', '14215', '11205', '10462', '10314']\n","\n","Retrying batch 2...\n","\n","--- Chunk 1/3: 10 zipcodes ---\n","  Selected 58 locations\n","  Problem size: 254 facilities, 58 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_2_chunk_1...\n","  ❌ retry_batch_2_chunk_1 INFEASIBLE\n","  Still infeasible: ['13603', '10701', '10458', '11717', '11372', '10466', '13440', '13502', '10461', '14211']\n","\n","--- Chunk 2/3: 10 zipcodes ---\n","  Selected 50 locations\n","  Problem size: 275 facilities, 50 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_2_chunk_2...\n","  ❌ retry_batch_2_chunk_2 INFEASIBLE\n","  Still infeasible: ['11377', '11221', '13501', '11233', '11722', '10306', '11365', '11236', '11550', '11229']\n","\n","--- Chunk 3/3: 5 zipcodes ---\n","  Selected 25 locations\n","  Problem size: 104 facilities, 25 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_2_chunk_3...\n","  ❌ retry_batch_2_chunk_3 INFEASIBLE\n","  Still infeasible: ['10472', '14580', '14213', '11224', '14621']\n","\n","Retrying batch 3...\n","\n","--- Chunk 1/3: 10 zipcodes ---\n","  Selected 45 locations\n","  Problem size: 211 facilities, 45 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_3_chunk_1...\n","  ❌ retry_batch_3_chunk_1 INFEASIBLE\n","  Still infeasible: ['10312', '10550', '11358', '11417', '13208', '11375', '14207', '11416', '10128', '14609']\n","\n","--- Chunk 2/3: 10 zipcodes ---\n","  Selected 40 locations\n","  Problem size: 220 facilities, 40 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_3_chunk_2...\n","  ❌ retry_batch_3_chunk_2 INFEASIBLE\n","  Still infeasible: ['10309', '11692', '11434', '11419', '11370', '11209', '11951', '11726', '12601', '11421']\n","\n","--- Chunk 3/3: 5 zipcodes ---\n","  Selected 17 locations\n","  Problem size: 82 facilities, 17 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_3_chunk_3...\n","  ❌ retry_batch_3_chunk_3 INFEASIBLE\n","  Still infeasible: ['14225', '10024', '11367', '11423', '14220']\n","\n","Retrying batch 4...\n","\n","--- Chunk 1/3: 10 zipcodes ---\n","  Selected 30 locations\n","  Problem size: 163 facilities, 30 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_4_chunk_1...\n","  ❌ retry_batch_4_chunk_1 INFEASIBLE\n","  Still infeasible: ['11950', '10031', '11429', '11436', '14206', '13069', '14612', '10028', '11378', '13204']\n","\n","--- Chunk 2/3: 10 zipcodes ---\n","  Selected 31 locations\n","  Problem size: 166 facilities, 31 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_4_chunk_2...\n","  ❌ retry_batch_4_chunk_2 INFEASIBLE\n","  Still infeasible: ['11356', '14212', '11776', '11235', '13901', '11354', '12550', '12901', '11427', '13206']\n","\n","--- Chunk 3/3: 5 zipcodes ---\n","  Selected 15 locations\n","  Problem size: 88 facilities, 15 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_4_chunk_3...\n","  ❌ retry_batch_4_chunk_3 INFEASIBLE\n","  Still infeasible: ['14450', '11225', '10022', '10467', '11010']\n","\n","Retrying batch 5...\n","\n","--- Chunk 1/3: 10 zipcodes ---\n","  Selected 31 locations\n","  Problem size: 118 facilities, 31 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_5_chunk_1...\n","  ✓ retry_batch_5_chunk_1: $3,672,000.00\n","\n","--- Chunk 2/3: 10 zipcodes ---\n","  Selected 30 locations\n","  Problem size: 162 facilities, 30 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_5_chunk_2...\n","  ❌ retry_batch_5_chunk_2 INFEASIBLE\n","  Still infeasible: ['13662', '13205', '14456', '11731', '14425', '11210', '13365', '11772', '13027', '11234']\n","\n","--- Chunk 3/3: 5 zipcodes ---\n","  Selected 15 locations\n","  Problem size: 70 facilities, 15 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_5_chunk_3...\n","  ❌ retry_batch_5_chunk_3 INFEASIBLE\n","  Still infeasible: ['11720', '12010', '12831', '10567', '11203']\n","\n","Retrying batch 6...\n","\n","--- Chunk 1/3: 10 zipcodes ---\n","  Selected 30 locations\n","  Problem size: 148 facilities, 30 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_6_chunk_1...\n","  ❌ retry_batch_6_chunk_1 INFEASIBLE\n","  Still infeasible: ['13357', '10308', '14304', '13212', '10457', '11784', '12801', '12304', '13126', '10512']\n","\n","--- Chunk 2/3: 10 zipcodes ---\n","  Selected 30 locations\n","  Problem size: 174 facilities, 30 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_6_chunk_2...\n","  ✓ retry_batch_6_chunk_2: $2,940,000.00\n","\n","--- Chunk 3/3: 5 zipcodes ---\n","  Selected 15 locations\n","  Problem size: 59 facilities, 15 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_6_chunk_3...\n","  ✓ retry_batch_6_chunk_3: $1,543,000.00\n","\n","Retrying batch 7...\n","\n","--- Chunk 1/3: 10 zipcodes ---\n","  Selected 30 locations\n","  Problem size: 146 facilities, 30 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_7_chunk_1...\n","  ✓ retry_batch_7_chunk_1: $2,796,000.00\n","\n","--- Chunk 2/3: 10 zipcodes ---\n","  Selected 30 locations\n","  Problem size: 137 facilities, 30 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_7_chunk_2...\n","  ❌ retry_batch_7_chunk_2 INFEASIBLE\n","  Still infeasible: ['11741', '13078', '10580', '14586', '14224', '13905', '11422', '11553', '11357', '14424']\n","\n","--- Chunk 3/3: 5 zipcodes ---\n","  Selected 15 locations\n","  Problem size: 80 facilities, 15 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_7_chunk_3...\n","  ✓ retry_batch_7_chunk_3: $1,362,000.00\n","\n","Retrying batch 10...\n","\n","--- Chunk 1/3: 10 zipcodes ---\n","  Selected 30 locations\n","  Problem size: 100 facilities, 30 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_10_chunk_1...\n","  ✓ retry_batch_10_chunk_1: $2,276,000.00\n","\n","--- Chunk 2/3: 10 zipcodes ---\n","  Selected 31 locations\n","  Problem size: 123 facilities, 31 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_10_chunk_2...\n","  ❌ retry_batch_10_chunk_2 INFEASIBLE\n","  Still infeasible: ['14032', '13790', '10451', '11217', '13029', '13803', '12839', '13316', '14724', '11218']\n","\n","--- Chunk 3/3: 5 zipcodes ---\n","  Selected 15 locations\n","  Problem size: 66 facilities, 15 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_10_chunk_3...\n","  ✓ retry_batch_10_chunk_3: $919,000.00\n","\n","Retrying batch 12...\n","\n","--- Chunk 1/3: 10 zipcodes ---\n","  Selected 30 locations\n","  Problem size: 136 facilities, 30 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_12_chunk_1...\n","  ❌ retry_batch_12_chunk_1 INFEASIBLE\n","  Still infeasible: ['13031', '10029', '11789', '12566', '11753', '10455', '11552', '14470', '10533', '11580']\n","\n","--- Chunk 2/3: 10 zipcodes ---\n","  Selected 30 locations\n","  Problem size: 74 facilities, 30 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_12_chunk_2...\n","  ✓ retry_batch_12_chunk_2: $1,837,000.00\n","\n","--- Chunk 3/3: 5 zipcodes ---\n","  Selected 15 locations\n","  Problem size: 14 facilities, 15 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_12_chunk_3...\n","  ✓ retry_batch_12_chunk_3: $955,000.00\n","\n","Retrying batch 16...\n","\n","--- Chunk 1/3: 10 zipcodes ---\n","  Selected 30 locations\n","  Problem size: 55 facilities, 30 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_16_chunk_1...\n","  ❌ retry_batch_16_chunk_1 INFEASIBLE\n","  Still infeasible: ['11596', '13114', '11755', '10916', '14057', '11954', '11771', '14001', '11212', '14132']\n","\n","--- Chunk 2/3: 10 zipcodes ---\n","  Selected 30 locations\n","  Problem size: 40 facilities, 30 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_16_chunk_2...\n","  ✓ retry_batch_16_chunk_2: $1,470,000.00\n","\n","--- Chunk 3/3: 5 zipcodes ---\n","  Selected 15 locations\n","  Problem size: 8 facilities, 15 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_16_chunk_3...\n","  ✓ retry_batch_16_chunk_3: $699,000.00\n","\n","Retrying batch 18...\n","\n","--- Chunk 1/3: 10 zipcodes ---\n","  Selected 30 locations\n","  Problem size: 21 facilities, 30 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_18_chunk_1...\n","  ✓ retry_batch_18_chunk_1: $1,218,000.00\n","\n","--- Chunk 2/3: 10 zipcodes ---\n","  Selected 30 locations\n","  Problem size: 45 facilities, 30 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_18_chunk_2...\n","  ✓ retry_batch_18_chunk_2: $1,146,000.00\n","\n","--- Chunk 3/3: 5 zipcodes ---\n","  Selected 15 locations\n","  Problem size: 33 facilities, 15 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_18_chunk_3...\n","  ❌ retry_batch_18_chunk_3 INFEASIBLE\n","  Still infeasible: ['13811', '13146', '14710', '13843', '11207']\n","\n","Retrying batch 21...\n","\n","--- Chunk 1/10: 10 zipcodes ---\n","  Selected 30 locations\n","  Problem size: 13 facilities, 30 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_21_chunk_1...\n","  ✓ retry_batch_21_chunk_1: $1,182,000.00\n","\n","--- Chunk 2/10: 10 zipcodes ---\n","  Selected 30 locations\n","  Problem size: 5 facilities, 30 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_21_chunk_2...\n","  ✓ retry_batch_21_chunk_2: $1,110,000.00\n","\n","--- Chunk 3/10: 10 zipcodes ---\n","  Selected 30 locations\n","  Problem size: 21 facilities, 30 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_21_chunk_3...\n","  ✓ retry_batch_21_chunk_3: $1,110,000.00\n","\n","--- Chunk 4/10: 10 zipcodes ---\n","  Selected 30 locations\n","  Problem size: 8 facilities, 30 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_21_chunk_4...\n","  ✓ retry_batch_21_chunk_4: $1,110,000.00\n","\n","--- Chunk 5/10: 10 zipcodes ---\n","  Selected 30 locations\n","  Problem size: 22 facilities, 30 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_21_chunk_5...\n","  ✓ retry_batch_21_chunk_5: $1,110,000.00\n","\n","--- Chunk 6/10: 10 zipcodes ---\n","  Selected 30 locations\n","  Problem size: 14 facilities, 30 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_21_chunk_6...\n","  ✓ retry_batch_21_chunk_6: $1,110,000.00\n","\n","--- Chunk 7/10: 10 zipcodes ---\n","  Selected 30 locations\n","  Problem size: 34 facilities, 30 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_21_chunk_7...\n","  ✓ retry_batch_21_chunk_7: $1,146,000.00\n","\n","--- Chunk 8/10: 10 zipcodes ---\n","  Selected 30 locations\n","  Problem size: 10 facilities, 30 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_21_chunk_8...\n","  ✓ retry_batch_21_chunk_8: $1,110,000.00\n","\n","--- Chunk 9/10: 10 zipcodes ---\n","  Selected 30 locations\n","  Problem size: 72 facilities, 30 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_21_chunk_9...\n","  ❌ retry_batch_21_chunk_9 INFEASIBLE\n","  Still infeasible: ['11215', '12149', '11040', '13077', '12582', '13167', '12962', '11783', '14036', '14033']\n","\n","--- Chunk 10/10: 10 zipcodes ---\n","  Selected 30 locations\n","  Problem size: 30 facilities, 30 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_21_chunk_10...\n","  ✓ retry_batch_21_chunk_10: $1,146,000.00\n","\n","Retrying batch 22...\n","\n","--- Chunk 1/10: 10 zipcodes ---\n","  Selected 30 locations\n","  Problem size: 45 facilities, 30 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_22_chunk_1...\n","  ✓ retry_batch_22_chunk_1: $1,219,000.00\n","\n","--- Chunk 2/10: 10 zipcodes ---\n","  Selected 30 locations\n","  Problem size: 49 facilities, 30 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_22_chunk_2...\n","  ✓ retry_batch_22_chunk_2: $918,000.00\n","\n","--- Chunk 3/10: 10 zipcodes ---\n","  Selected 30 locations\n","  Problem size: 21 facilities, 30 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_22_chunk_3...\n","  ✓ retry_batch_22_chunk_3: $768,000.00\n","\n","--- Chunk 4/10: 10 zipcodes ---\n","  Selected 30 locations\n","  Problem size: 43 facilities, 30 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_22_chunk_4...\n","  ❌ retry_batch_22_chunk_4 INFEASIBLE\n","  Still infeasible: ['12193', '12918', '11520', '13036', '11941', '11933', '12733', '13754', '12458', '13110']\n","\n","--- Chunk 5/10: 10 zipcodes ---\n","  Selected 30 locations\n","  Problem size: 20 facilities, 30 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_22_chunk_5...\n","  ✓ retry_batch_22_chunk_5: $844,000.00\n","\n","--- Chunk 6/10: 10 zipcodes ---\n","  Selected 30 locations\n","  Problem size: 11 facilities, 30 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_22_chunk_6...\n","  ✓ retry_batch_22_chunk_6: $806,000.00\n","\n","--- Chunk 7/10: 10 zipcodes ---\n","  Selected 30 locations\n","  Problem size: 5 facilities, 30 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_22_chunk_7...\n","  ✓ retry_batch_22_chunk_7: $806,000.00\n","\n","--- Chunk 8/10: 10 zipcodes ---\n","  Selected 30 locations\n","  Problem size: 9 facilities, 30 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_22_chunk_8...\n","  ✓ retry_batch_22_chunk_8: $730,000.00\n","\n","--- Chunk 9/10: 10 zipcodes ---\n","  Selected 30 locations\n","  Problem size: 14 facilities, 30 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_22_chunk_9...\n","  ✓ retry_batch_22_chunk_9: $730,000.00\n","\n","--- Chunk 10/10: 10 zipcodes ---\n","  Selected 30 locations\n","  Problem size: 13 facilities, 30 locations\n","Set parameter TimeLimit to value 600\n","  Solving retry_batch_22_chunk_10...\n","  ✓ retry_batch_22_chunk_10: $768,000.00\n","\n","============================================================\n","FINAL RESULTS\n","============================================================\n","Expansions: 3413\n","New builds: 1031\n","Zipcodes meeting threshold: 897/897\n","Total cost: $223,383,827.52\n","Unsolved zipcodes: 190\n","\n","============================================================\n","DONE\n","============================================================\n"]}]},{"cell_type":"code","source":["\"\"\"\n","Diagnostic tool to understand why certain zipcodes cause infeasibility\n","\"\"\"\n","\n","import pandas as pd\n","import os\n","\n","# Assuming OUTPUT_PATH is defined\n","# OUTPUT_PATH = '/content/drive/MyDrive/IEORE4004 Optimization Models and Methods/IEOR4404_Proj1/cleaned_data/'\n","\n","try:\n","    master = pd.read_csv(os.path.join(OUTPUT_PATH, 'zipcode_master.csv'), dtype={'zipcode': str})\n","    fac = pd.read_csv(os.path.join(OUTPUT_PATH, 'facilities_clean.csv'))\n","    locs = pd.read_csv(os.path.join(OUTPUT_PATH, 'locations_clean.csv'))\n","except Exception as e:\n","    print(f\"Error loading data: {e}\")\n","    exit(1)\n","\n","# Normalize zipcode formats\n","for df in [master, fac, locs]:\n","    if 'zipcode' in df.columns:\n","        df['zipcode'] = df['zipcode'].astype(str).str.zfill(5)\n","\n","# Parameters\n","MAX_FACILITIES_PER_ZIP = 20\n","EXPANSION_CAP_FRAC = 0.20\n","\n","print(\"=\"*70)\n","print(\"INFEASIBILITY DIAGNOSTIC\")\n","print(\"=\"*70)\n","\n","# Analyze the problematic zipcode(s)\n","problem_zips = ['10952']  # From IIS output\n","\n","for z in problem_zips:\n","    print(f\"\\n{'='*70}\")\n","    print(f\"Analyzing Zipcode: {z}\")\n","    print(f\"{'='*70}\")\n","\n","    if z not in master['zipcode'].values:\n","        print(f\"  ⚠ Zipcode {z} not found in master data\")\n","        continue\n","\n","    zip_data = master[master['zipcode'] == z].iloc[0]\n","\n","    # Population and thresholds\n","    pop_0_12 = float(zip_data['pop_0_12'])\n","    pop_0_5 = float(zip_data['pop_0_5'])\n","    desert_threshold = float(zip_data['desert_threshold'])\n","    current_slots = float(zip_data['total_existing_slots'])\n","    need = desert_threshold - current_slots\n","\n","    print(f\"\\n📊 DEMAND:\")\n","    print(f\"  Population 0-12: {pop_0_12:.0f}\")\n","    print(f\"  Population 0-5: {pop_0_5:.0f}\")\n","    print(f\"  Desert threshold (required): {desert_threshold:.0f}\")\n","    print(f\"  Current slots: {current_slots:.0f}\")\n","    print(f\"  Unmet need: {need:.0f}\")\n","\n","    # Existing facilities\n","    existing_facs = fac[fac['zipcode'] == z].copy()\n","    print(f\"\\n🏢 EXISTING FACILITIES:\")\n","    print(f\"  Total facilities in zip: {len(existing_facs)}\")\n","\n","    if len(existing_facs) > 0:\n","        existing_facs = existing_facs.sort_values('capacity', ascending=False)\n","        top_facs = existing_facs.head(MAX_FACILITIES_PER_ZIP)\n","\n","        print(f\"  Top {MAX_FACILITIES_PER_ZIP} facilities (by capacity):\")\n","        total_current_capacity = 0\n","        total_max_expansion = 0\n","\n","        for idx, row in top_facs.iterrows():\n","            cap = int(row['capacity'])\n","            max_exp = int(cap * EXPANSION_CAP_FRAC)\n","            total_current_capacity += cap\n","            total_max_expansion += max_exp\n","            print(f\"    Facility {row['facility_id']}: capacity={cap}, max_expansion={max_exp}\")\n","\n","        print(f\"\\n  Summary of top {len(top_facs)} facilities:\")\n","        print(f\"    Current capacity: {total_current_capacity}\")\n","        print(f\"    Max expansion (20%): {total_max_expansion}\")\n","        print(f\"    Max total after expansion: {total_current_capacity + total_max_expansion}\")\n","    else:\n","        print(f\"  ⚠ NO existing facilities in this zipcode!\")\n","        total_current_capacity = 0\n","        total_max_expansion = 0\n","\n","    # Potential new locations\n","    potential_locs = locs[locs['zipcode'] == z]\n","    print(f\"\\n📍 POTENTIAL NEW LOCATIONS:\")\n","    print(f\"  Available locations: {len(potential_locs)}\")\n","\n","    # Maximum possible from new builds (assuming all large facilities)\n","    max_new_capacity = len(potential_locs) * 400  # 400 = max slots for large facility\n","    print(f\"  Max capacity if all locations built as 'large': {max_new_capacity}\")\n","\n","    # Supply vs Demand Analysis\n","    print(f\"\\n⚖️ SUPPLY vs DEMAND:\")\n","    print(f\"  Current capacity: {total_current_capacity}\")\n","    print(f\"  + Max expansion: {total_max_expansion}\")\n","    print(f\"  + Max new builds: {max_new_capacity}\")\n","    print(f\"  = Max total supply: {total_current_capacity + total_max_expansion + max_new_capacity}\")\n","    print(f\"  Required (threshold): {desert_threshold}\")\n","\n","    gap = (total_current_capacity + total_max_expansion + max_new_capacity) - desert_threshold\n","\n","    if gap >= 0:\n","        print(f\"  ✓ SUFFICIENT: Surplus of {gap:.0f} slots\")\n","    else:\n","        print(f\"  ❌ INSUFFICIENT: Deficit of {abs(gap):.0f} slots\")\n","        print(f\"\\n  🔍 ROOT CAUSE:\")\n","        if len(existing_facs) == 0:\n","            print(f\"    - No existing facilities to expand\")\n","        if len(potential_locs) == 0:\n","            print(f\"    - No potential locations for new builds\")\n","        if gap < 0:\n","            print(f\"    - Even with maximum expansion and all new builds, cannot meet threshold\")\n","\n","    # 0-5 constraint check\n","    min_slots_0_5 = pop_0_5 * (2.0/3.0)\n","    # Approximate: 50% of existing + expansions serve 0-5, new builds have explicit 0-5 capacity\n","    # The variables expansion_slots and new_slots_0_5 are defined in the previous cell (qn_0-PkPLfwe)\n","    # Since this is a diagnostic tool, we can approximate or assume these values based on max potential\n","    # For a more accurate check, these would need to be calculated within this cell or passed as parameters.\n","    # For now, we'll use maximum potential values for a simplified check.\n","    expansion_0_5_approx = total_max_expansion * 0.8 # Assuming 80% of expanded slots are for 0-5\n","    max_new_0_5 = len(potential_locs) * 320 # Max 0-5 slots for large facility is 320\n","\n","    total_0_5_max = (total_current_capacity * 0.8) + expansion_0_5_approx + max_new_0_5 # Assuming 80% of current capacity is for 0-5\n","\n","    print(f\"\\n👶 0-5 AGE GROUP CONSTRAINT:\")\n","    print(f\"  Required (2/3 of pop_0_5): {min_slots_0_5:.0f}\")\n","    print(f\"  Max possible 0-5 slots: {total_0_5_max:.0f}\")\n","\n","    gap_0_5 = total_0_5_max - min_slots_0_5\n","    if gap_0_5 >= 0:\n","        print(f\"  ✓ SUFFICIENT: Surplus of {gap_0_5:.0f} slots\")\n","    else:\n","        print(f\"  ❌ INSUFFICIENT: Deficit of {abs(gap_0_5):.0f} slots\")\n","\n","print(f\"\\n{'='*70}\")\n","print(\"RECOMMENDATIONS:\")\n","print(f\"{'='*70}\")\n","\n","for z in problem_zips:\n","    if z not in master['zipcode'].values:\n","        continue\n","\n","    zip_data = master[master['zipcode'] == z].iloc[0]\n","    desert_threshold = float(zip_data['desert_threshold'])\n","    current_slots = float(zip_data['total_existing_slots'])\n","\n","    existing_facs = fac[fac['zipcode'] == z]\n","    potential_locs = locs[locs['zipcode'] == z]\n","\n","    top_facs = existing_facs.sort_values('capacity', ascending=False).head(MAX_FACILITIES_PER_ZIP)\n","    total_current = top_facs['capacity'].sum() if len(top_facs) > 0 else 0\n","    max_expansion = int(total_current * EXPANSION_CAP_FRAC)\n","    max_new = len(potential_locs) * 400\n","\n","    max_total = total_current + max_expansion + max_new\n","\n","    if max_total < desert_threshold:\n","        print(f\"\\nZipcode {z}:\")\n","        print(f\"  1. ❌ INFEASIBLE - Cannot meet threshold even with all options\")\n","        print(f\"     Solutions:\")\n","        print(f\"       a) Increase EXPANSION_CAP_FRAC from 0.20 to 0.30 or higher\")\n","        print(f\"       b) Include facilities from neighboring zipcodes (relaxed distance)\")\n","        print(f\"       c) Consider this zipcode acceptable as 'high-need desert' in reporting\")\n","        print(f\"       d) Add more potential locations to this zipcode\")\n","    else:\n","        print(f\"\\nZipcode {z}:\")\n","        print(f\"  ✓ Feasible in theory, but may have other issues:\")\n","        print(f\"    - Check distance constraints (MIN_DISTANCE_MILES)\")\n","        print(f\"    - Check 0-5 capacity requirements\")\n","        print(f\"    - Increase MAX_FACILITIES_PER_ZIP to include more facilities\")\n","\n","print(f\"\\n{'='*70}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Q84eJ9OlJg-","executionInfo":{"status":"ok","timestamp":1762202004939,"user_tz":300,"elapsed":197,"user":{"displayName":"Victor Tenneroni","userId":"03459946062708176020"}},"outputId":"4e59e50e-d815-4fb1-e612-e4c2e4367e6a"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","INFEASIBILITY DIAGNOSTIC\n","======================================================================\n","\n","======================================================================\n","Analyzing Zipcode: 10952\n","======================================================================\n","\n","📊 DEMAND:\n","  Population 0-12: 16082\n","  Population 0-5: 7131\n","  Desert threshold (required): 5307\n","  Current slots: 581\n","  Unmet need: 4726\n","\n","🏢 EXISTING FACILITIES:\n","  Total facilities in zip: 31\n","  Top 20 facilities (by capacity):\n","    Facility 533013: capacity=123, max_expansion=24\n","    Facility 848103: capacity=16, max_expansion=3\n","    Facility 905995: capacity=16, max_expansion=3\n","    Facility 746053: capacity=16, max_expansion=3\n","    Facility 848300: capacity=16, max_expansion=3\n","    Facility 467838: capacity=16, max_expansion=3\n","    Facility 148121: capacity=16, max_expansion=3\n","    Facility 847334: capacity=16, max_expansion=3\n","    Facility 847612: capacity=16, max_expansion=3\n","    Facility 849148: capacity=16, max_expansion=3\n","    Facility 35664: capacity=16, max_expansion=3\n","    Facility 843007: capacity=16, max_expansion=3\n","    Facility 27131: capacity=16, max_expansion=3\n","    Facility 349674: capacity=16, max_expansion=3\n","    Facility 752596: capacity=16, max_expansion=3\n","    Facility 889562: capacity=16, max_expansion=3\n","    Facility 883431: capacity=16, max_expansion=3\n","    Facility 914699: capacity=16, max_expansion=3\n","    Facility 860320: capacity=16, max_expansion=3\n","    Facility 402174: capacity=16, max_expansion=3\n","\n","  Summary of top 20 facilities:\n","    Current capacity: 427\n","    Max expansion (20%): 81\n","    Max total after expansion: 508\n","\n","📍 POTENTIAL NEW LOCATIONS:\n","  Available locations: 100\n","  Max capacity if all locations built as 'large': 40000\n","\n","⚖️ SUPPLY vs DEMAND:\n","  Current capacity: 427\n","  + Max expansion: 81\n","  + Max new builds: 40000\n","  = Max total supply: 40508\n","  Required (threshold): 5307.06\n","  ✓ SUFFICIENT: Surplus of 35201 slots\n","\n","👶 0-5 AGE GROUP CONSTRAINT:\n","  Required (2/3 of pop_0_5): 4754\n","  Max possible 0-5 slots: 32406\n","  ✓ SUFFICIENT: Surplus of 27652 slots\n","\n","======================================================================\n","RECOMMENDATIONS:\n","======================================================================\n","\n","Zipcode 10952:\n","  ✓ Feasible in theory, but may have other issues:\n","    - Check distance constraints (MIN_DISTANCE_MILES)\n","    - Check 0-5 capacity requirements\n","    - Increase MAX_FACILITIES_PER_ZIP to include more facilities\n","\n","======================================================================\n"]}]},{"cell_type":"code","source":["# params = {\n","# \"WLSACCESSID\": \"b92cfff8-0279-4652-9cb7-3e6bcdb967cd\",\n","# \"WLSSECRET\":\"e6220bd1-2657-40f8-ba01-6cebcb97db7f\",\n","# \"LICENSEID\":2726201,\n","# }\n","# env = gp.Env(params=params)\n"],"metadata":{"id":"Ck_sYm-JX8Nb","executionInfo":{"status":"ok","timestamp":1762202004942,"user_tz":300,"elapsed":2,"user":{"displayName":"Victor Tenneroni","userId":"03459946062708176020"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"R_rH7P2VYCO8","executionInfo":{"status":"ok","timestamp":1762202004965,"user_tz":300,"elapsed":22,"user":{"displayName":"Victor Tenneroni","userId":"03459946062708176020"}}},"execution_count":7,"outputs":[]}]}